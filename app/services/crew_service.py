from crewai import Crew, Process
from typing import Dict, Any, Optional, List
import json
import os
import logging
from datetime import datetime

logger = logging.getLogger(__name__)

from .agents import (
    create_extractor_agent,
    create_classifier_agent,
    create_generator_agent,
    create_validator_agent
)
from .tasks import (
    create_extraction_task,
    create_classification_task,
    create_generation_task,
    create_validation_task,
    create_revision_task,
    create_self_reflection_task
)
from app.models.agent_state import AgentState


class BiddingDocumentCrew:
    """
    ì…ì°° ê³µê³ ë¬¸ ìë™ ì‘ì„± Crew (ë©€í‹° ì—ì´ì „íŠ¸ êµ¬ì¡°)
    
    í˜„ì¬ êµ¬ì¡°: ìˆœì°¨ì  ë©€í‹° ì—ì´ì „íŠ¸
    - ê° ë‹¨ê³„ë§ˆë‹¤ ë³„ë„ì˜ Crew ìƒì„± (Extractor â†’ Classifier â†’ Generator â†’ Validator)
    - Agentë“¤ì´ ìˆœì°¨ì ìœ¼ë¡œ í˜‘ì—…í•˜ì—¬ ì „ì²´ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
    
    í–¥í›„ ê°œì„  ê°€ëŠ¥: í˜‘ì—…ì  ë©€í‹° ì—ì´ì „íŠ¸
    - ì—¬ëŸ¬ Agentê°€ í•œ Crewì— í•¨ê»˜ ìˆì–´ì„œ ë™ì‹œì— í˜‘ì—…
    - Task ê°„ ì˜ì¡´ì„± ì„¤ì •ìœ¼ë¡œ ë” ìœ ì—°í•œ í˜‘ì—… ê°€ëŠ¥
    """

    def __init__(self, state: AgentState):
        self.state = state
        self.extractor = create_extractor_agent()
        self.classifier = create_classifier_agent()
        self.generator = create_generator_agent()
        self.validator = create_validator_agent()

    def run_extraction(self, document_text: str) -> Dict[str, Any]:
        """
        STEP 2: ë¬¸ì„œì—ì„œ ì •ë³´ ì¶”ì¶œ

        Returns:
            ExtractedData í˜•ì‹ì˜ ë”•ì…”ë„ˆë¦¬
        """
        task = create_extraction_task(self.extractor, document_text)

        crew = Crew(
            agents=[self.extractor],
            tasks=[task],
            process=Process.sequential,
            verbose=True
        )

        result = crew.kickoff()

        # ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ íŒŒì‹±
        try:
            extracted_data = json.loads(str(result))
        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ raw_outputì—ì„œ JSON ì¶”ì¶œ ì‹œë„
            import re
            result_str = str(result)
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', result_str, re.DOTALL)
            if json_match:
                try:
                    extracted_data = json.loads(json_match.group(1))
                except json.JSONDecodeError:
                    extracted_data = {"raw_output": result_str}
            else:
                extracted_data = {"raw_output": result_str}

        # AgentState ì—…ë°ì´íŠ¸
        self.state.extracted_data = extracted_data
        self.state.transition_to("classify")

        return extracted_data

    def run_classification(self, extracted_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        STEP 3: ê³µê³  ìœ í˜• ë¶„ë¥˜ (Classifier Agent + Rule Engine Tool)
        
        Classifier Agentê°€ Rule Engine Toolì„ ì‚¬ìš©í•˜ì—¬ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        1ì°¨ ë¶„ê¸°: ê³µê³  ë°©ì‹ (ì†Œì•¡ìˆ˜ì˜/ì ê²©ì‹¬ì‚¬)
        2ì°¨ ë¶„ê¸°: ê³„ì•½ ì„±ê²© (êµ­ê°€ê³„ì•½/ë‹¨ê°€ê³„ì•½, ë‹¨ë…/ê³µë™)

        Returns:
            ClassificationResult í˜•ì‹ì˜ ë”•ì…”ë„ˆë¦¬
        """
        import json
        
        # Classifier Agentê°€ Rule Engine Toolì„ ì‚¬ìš©í•˜ë„ë¡ Task ìƒì„±
        task = create_classification_task(
            self.classifier,
            extracted_data
        )
        
        # Classifier Agentë§Œ ì‚¬ìš© (Rule Engineì€ Toolë¡œ ì œê³µ)
        crew = Crew(
            agents=[self.classifier],
            tasks=[task],
            process=Process.sequential,
            verbose=True
        )
        
        result = crew.kickoff()
        
        # ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ íŒŒì‹±
        try:
            result_str = str(result)
            # JSON ë¬¸ìì—´ ì§ì ‘ íŒŒì‹± ì‹œë„
            try:
                classification = json.loads(result_str)
            except json.JSONDecodeError:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ raw_outputì—ì„œ JSON ì¶”ì¶œ ì‹œë„
                import re
                # ```json ... ``` ë¸”ë¡ ì°¾ê¸°
                json_block_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', result_str, re.DOTALL)
                if json_block_match:
                    try:
                        classification = json.loads(json_block_match.group(1))
                    except json.JSONDecodeError:
                        # ì¤‘ì²©ëœ JSON ì°¾ê¸° ì‹œë„
                        pass
                
                # ì•„ì§ íŒŒì‹±ë˜ì§€ ì•Šì•˜ë‹¤ë©´ {...} íŒ¨í„´ ì°¾ê¸°
                if 'classification' not in locals() or not isinstance(classification, dict):
                    # ì²« ë²ˆì§¸ { ë¶€í„° ì‹œì‘í•˜ëŠ” JSON ê°ì²´ ì°¾ê¸°
                    brace_start = result_str.find('{')
                    if brace_start != -1:
                        brace_count = 0
                        brace_end = brace_start
                        for i in range(brace_start, len(result_str)):
                            if result_str[i] == '{':
                                brace_count += 1
                            elif result_str[i] == '}':
                                brace_count -= 1
                                if brace_count == 0:
                                    brace_end = i + 1
                                    break
                        
                        if brace_end > brace_start:
                            try:
                                classification = json.loads(result_str[brace_start:brace_end])
                            except json.JSONDecodeError:
                                raise json.JSONDecodeError("No valid JSON found in result", result_str, 0)
                    else:
                        raise json.JSONDecodeError("No JSON found in result", result_str, 0)
            
            # Agent ê²°ê³¼ ê²€ì¦: ê¸ˆì•¡ì´ 0ì´ë©´ fallback ì‚¬ìš©
            if classification.get("estimated_price_exc_vat") == 0 or classification.get("total_budget_vat") == 0:
                print("âš ï¸ Classifier Agent ê²°ê³¼ì— ê¸ˆì•¡ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. Rule Engine ì§ì ‘ í˜¸ì¶œ...")
                raise ValueError("Invalid classification result")
        except (json.JSONDecodeError, ValueError, KeyError) as e:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ë˜ëŠ” ìœ íš¨í•˜ì§€ ì•Šì€ ê²°ê³¼ ì‹œ Rule Engine ì§ì ‘ í˜¸ì¶œ (fallback)
            print(f"âš ï¸ Classifier Agent ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨ ë˜ëŠ” ìœ íš¨í•˜ì§€ ì•ŠìŒ: {e}. Rule Engine ì§ì ‘ í˜¸ì¶œ...")
            from app.tools.rule_engine import get_rule_engine
            from app.models.schemas import ExtractedData
            
            # extracted_dataì—ì„œ raw_output íŒŒì‹± ì‹œë„
            parsed_data = extracted_data.copy()
            if "raw_output" in extracted_data and isinstance(extracted_data["raw_output"], str):
                try:
                    # raw_outputì—ì„œ JSON ì¶”ì¶œ ì‹œë„
                    import re
                    json_match = re.search(r'```json\s*(\{.*?\})\s*```', extracted_data["raw_output"], re.DOTALL)
                    if json_match:
                        raw_json = json.loads(json_match.group(1))
                        # raw_jsonì˜ ê°’ìœ¼ë¡œ parsed_data ì—…ë°ì´íŠ¸ (ê¸°ì¡´ ê°’ì´ ì—†ì„ ë•Œë§Œ)
                        for key, value in raw_json.items():
                            if key not in parsed_data or not parsed_data[key]:
                                parsed_data[key] = value
                except Exception as parse_error:
                    print(f"âš ï¸ raw_output íŒŒì‹± ì‹¤íŒ¨: {parse_error}")
            
            # ë°ì´í„° íƒ€ì… ì •ê·œí™” (ExtractedData ìŠ¤í‚¤ë§ˆì— ë§ê²Œ)
            # qualification_notesê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
            if "qualification_notes" in parsed_data:
                if isinstance(parsed_data["qualification_notes"], list):
                    parsed_data["qualification_notes"] = "\n".join(str(item) for item in parsed_data["qualification_notes"])
                elif isinstance(parsed_data["qualification_notes"], dict):
                    # dictì¸ ê²½ìš° JSON ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ê±°ë‚˜ ê°’ë“¤ì„ ì¡°í•©
                    try:
                        parsed_data["qualification_notes"] = json.dumps(parsed_data["qualification_notes"], ensure_ascii=False)
                    except:
                        # JSON ì§ë ¬í™” ì‹¤íŒ¨ ì‹œ í‚¤-ê°’ ìŒì„ ë¬¸ìì—´ë¡œ ë³€í™˜
                        parsed_data["qualification_notes"] = "\n".join(f"{k}: {v}" for k, v in parsed_data["qualification_notes"].items())
                elif not isinstance(parsed_data["qualification_notes"], str):
                    # ê·¸ ì™¸ì˜ íƒ€ì…ì´ë©´ ë¬¸ìì—´ë¡œ ë³€í™˜
                    parsed_data["qualification_notes"] = str(parsed_data["qualification_notes"])
            
            # detail_item_codesì™€ industry_codesê°€ ë¬¸ìì—´ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            if "detail_item_codes" in parsed_data:
                if isinstance(parsed_data["detail_item_codes"], str):
                    parsed_data["detail_item_codes"] = [parsed_data["detail_item_codes"]] if parsed_data["detail_item_codes"] else []
                elif parsed_data["detail_item_codes"] is None:
                    parsed_data["detail_item_codes"] = []
                    
            if "industry_codes" in parsed_data:
                if isinstance(parsed_data["industry_codes"], str):
                    parsed_data["industry_codes"] = [parsed_data["industry_codes"]] if parsed_data["industry_codes"] else []
                elif parsed_data["industry_codes"] is None:
                    parsed_data["industry_codes"] = []
            
            try:
                extracted_model = ExtractedData(**parsed_data)
            except Exception as e:
                print(f"âš ï¸ ExtractedData ë³€í™˜ ì‹¤íŒ¨: {e}")
                # ìµœì†Œí•œì˜ í•„ë“œë¡œ ExtractedData ìƒì„±
                extracted_model = ExtractedData(
                    procurement_type=parsed_data.get("procurement_type", "ë¬¼í’ˆ"),
                    total_budget_vat=parsed_data.get("total_budget_vat") or parsed_data.get("estimated_amount", 0),
                    estimated_amount=parsed_data.get("estimated_amount", 0),
                    item_name=parsed_data.get("item_name", ""),
                    project_name=parsed_data.get("project_name", ""),
                    delivery_deadline_days=parsed_data.get("delivery_deadline_days"),
                    procurement_method_raw=parsed_data.get("procurement_method_raw", ""),
                    detail_item_codes=parsed_data.get("detail_item_codes", []),
                    industry_codes=parsed_data.get("industry_codes", []),
                    is_joint_contract=parsed_data.get("is_joint_contract", False),
                    has_region_restriction=parsed_data.get("has_region_restriction", False),
                    qualification_notes=parsed_data.get("qualification_notes", "")
                )
            
            rule_engine = get_rule_engine()
            classification_result = rule_engine.classify(extracted_model)
            contract_nature = rule_engine._determine_contract_nature(extracted_model)
            total_budget = extracted_model.total_budget_vat or extracted_model.estimated_amount
            estimated_price_exc_vat = rule_engine._calculate_estimated_price_exc_vat(total_budget)
            
            classification = {
                "recommended_type": classification_result.recommended_type,
                "confidence": classification_result.confidence,
                "reason": classification_result.reason,
                "alternative_types": classification_result.alternative_types,
                "reason_trace": classification_result.reason_trace,
                "contract_nature": contract_nature,
                "purchase_type": extracted_model.procurement_type,
                "estimated_price_exc_vat": estimated_price_exc_vat,
                "applied_annex": rule_engine._determine_annex(estimated_price_exc_vat),
                "sme_restriction": rule_engine._determine_sme_restriction(estimated_price_exc_vat)
            }
        
        print(f"\nâœ… ë¶„ë¥˜ ê²°ê³¼:")
        print(f"  - ê³µê³  ë°©ì‹: {classification.get('recommended_type', 'N/A')}")
        print(f"  - ê³„ì•½ ì„±ê²©: {classification.get('contract_nature', 'N/A')}")
        print(f"  - ì¶”ì •ê°€ê²©(VAT ì œì™¸): {classification.get('estimated_price_exc_vat', 0):,.0f}ì›")
        print(f"  - ì ìš© ë³„í‘œ: {classification.get('applied_annex', 'N/A')}")
        print(f"  - ì¤‘ì†Œê¸°ì—… ì œí•œ: {classification.get('sme_restriction', 'N/A')}")

        # AgentState ì—…ë°ì´íŠ¸
        self.state.classification = classification
        self.state.transition_to("generate")

        return classification

    def run_generation(
        self,
        extracted_data: Dict[str, Any],
        template_id: str = None,
        announcement_type: str = None,
        law_references: str = "",
        template_info: Dict[str, Any] = None,
        output_format: str = "markdown"
    ) -> str:
        """
        STEP 4: Document Assembly (Non-LLM Pipeline ë‹¨ê³„)
        
        í•µì‹¬ ì›ì¹™: "LLMì€ íŒë‹¨ë§Œ, ë¬¸ì„œ ìƒì„±ì€ ì½”ë“œê°€ í•œë‹¤"
        
        ì´ ë©”ì„œë“œëŠ” LLM Taskê°€ ì•„ë‹ˆë¼ Pipeline ë‹¨ê³„ì…ë‹ˆë‹¤:
        1. í…œí”Œë¦¿ íŒŒì¼ ì§ì ‘ ë¡œë“œ
        2. field_mapperë¡œ í”Œë ˆì´ìŠ¤í™€ë” ì¹˜í™˜ (Document Assembly)
        3. (ì„ íƒ) Generator Agentë¡œ ê²€ì¦/ë‹¤ë“¬ê¸° (USE_GENERATOR_AGENT=trueì¸ ê²½ìš°ë§Œ)
        
        Generator Agentì˜ ì—­í• :
        - âŒ ë¬¸ì„œ ìƒì„± (ì´ë¯¸ field_mapperê°€ ì™„ë£Œ)
        - âœ… ì„ íƒì  ê²€ì¦: í•„ìˆ˜ ìŠ¬ë¡¯ ëˆ„ë½ ì—¬ë¶€, ë¬¸ë§¥ ê²€ì¦
        - âœ… ì„ íƒì  ë‹¤ë“¬ê¸°: ë¬¸ì¥ íë¦„ ê°œì„  (ìœ„í—˜: í…œí”Œë¦¿ ìˆ˜ì • ê°€ëŠ¥)
        
        Args:
            extracted_data: ì¶”ì¶œëœ í‚¤ì›Œë“œ
            template_id: (ì‚¬ìš© ì•ˆ í•¨, í˜¸í™˜ì„± ìœ ì§€ìš©)
            announcement_type: ê³µê³  ìœ í˜• (í…œí”Œë¦¿ ì„ íƒìš©)

        Returns:
            ìƒì„±ëœ ê³µê³ ë¬¸ ë¬¸ìì—´ (field_mapper ê²°ê³¼ ë˜ëŠ” Generator Agent ê²°ê³¼)
        """
        from app.tools.template_selector import get_template_selector
        from app.tools.field_mapper import get_field_mapper
        from app.models.schemas import ClassificationResult, DocumentTemplate
        from app.infra.db.database import get_db
        from app.infra.db.models import NoticeTemplate

        # 1. í…œí”Œë¦¿ ì„ íƒ (ë¶„ë¥˜ ê²°ê³¼ ê¸°ë°˜)
        classification = self.state.classification or {}
        if not announcement_type:
            announcement_type = classification.get("recommended_type", "ì ê²©ì‹¬ì‚¬")

        # ClassificationResult ê°ì²´ ìƒì„± (í…œí”Œë¦¿ ì„ íƒìš©)
        classification_result = ClassificationResult(
            recommended_type=announcement_type,
            confidence=classification.get("confidence", 1.0),
            reason=classification.get("reason", ""),
            alternative_types=classification.get("alternative_types", [])
        )
        
        # í…œí”Œë¦¿ ë¡œë“œ ìš°ì„ ìˆœìœ„:
        # 1. template_infoì— template_idê°€ ìˆìœ¼ë©´ DBì—ì„œ í•´ë‹¹ IDë¡œ ì¡°íšŒ
        # 2. template_idê°€ ì—†ìœ¼ë©´ DBì—ì„œ ìµœì‹  í…œí”Œë¦¿ ì¡°íšŒ
        # 3. DBì—ë„ ì—†ìœ¼ë©´ íŒŒì¼ ì‹œìŠ¤í…œ ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©
        template = None
        template_content = None
        
        # 1. template_idë¡œ DBì—ì„œ ì¡°íšŒ
        if template_info and template_info.get("template_id"):
            db_template_id = template_info.get("template_id")
            try:
                db = next(get_db())
                # IDë¡œ ì¡°íšŒí•˜ê³ , template_typeë„ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸ (ì•ˆì „ì„±)
                db_template = (
                    db.query(NoticeTemplate)
                    .filter(NoticeTemplate.id == db_template_id)
                    .filter(NoticeTemplate.template_type == announcement_type)
                    .first()
                )
                if db_template:
                    template_content = db_template.content
                    template = DocumentTemplate(
                        template_id=f"db_template_{announcement_type}_{db_template.id}",
                        template_type=announcement_type,
                        content=template_content,
                        placeholders=[],
                        template_format="md",
                        template_path=None
                    )
                    print(f"âœ… DBì—ì„œ ì§€ì •ëœ í…œí”Œë¦¿ ë¡œë“œ: ID={db_template_id}, ìœ í˜•={announcement_type}, ë²„ì „={db_template.version}")
                else:
                    # IDëŠ” ìˆì§€ë§Œ template_typeì´ ë‹¤ë¥¸ ê²½ìš°
                    check_template = db.query(NoticeTemplate).filter(NoticeTemplate.id == db_template_id).first()
                    if check_template:
                        print(f"âš ï¸ ì§€ì •ëœ í…œí”Œë¦¿ ID({db_template_id})ëŠ” ì¡´ì¬í•˜ì§€ë§Œ, ìœ í˜•ì´ ë‹¤ë¦…ë‹ˆë‹¤. (ìš”ì²­: {announcement_type}, ì‹¤ì œ: {check_template.template_type})")
                    else:
                        print(f"âš ï¸ ì§€ì •ëœ í…œí”Œë¦¿ ID({db_template_id})ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    print(f"   ìµœì‹  í…œí”Œë¦¿ ì‚¬ìš©")
            except Exception as db_error:
                print(f"âš ï¸ DB í…œí”Œë¦¿ ì¡°íšŒ ì‹¤íŒ¨: {str(db_error)}")
        
        # 2. template_idê°€ ì—†ê±°ë‚˜ ì§€ì •ëœ í…œí”Œë¦¿ì„ ì°¾ì§€ ëª»í•œ ê²½ìš°, DBì—ì„œ ìµœì‹  í…œí”Œë¦¿ ì¡°íšŒ
        if not template:
            try:
                db = next(get_db())
                latest_template = (
                    db.query(NoticeTemplate)
                    .filter(NoticeTemplate.template_type == announcement_type)
                    .order_by(NoticeTemplate.created_at.desc())
                    .first()
                )
                if latest_template:
                    template_content = latest_template.content
                    template = DocumentTemplate(
                        template_id=f"db_template_{announcement_type}_{latest_template.id}",
                        template_type=announcement_type,
                        content=template_content,
                        placeholders=[],
                        template_format="md",
                        template_path=None
                    )
                    print(f"âœ… DBì—ì„œ ìµœì‹  í…œí”Œë¦¿ ë¡œë“œ: {announcement_type} (ë²„ì „: {latest_template.version}, ìƒì„±ì¼: {latest_template.created_at})")
            except Exception as db_error:
                print(f"âš ï¸ DB í…œí”Œë¦¿ ì¡°íšŒ ì‹¤íŒ¨: {str(db_error)}")
        
        # 3. DBì—ë„ ì—†ìœ¼ë©´ íŒŒì¼ ì‹œìŠ¤í…œ ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©
        if not template:
            template_selector = get_template_selector()
            import sys
            preferred_format = "md" if sys.platform != "win32" else "hwpx"
            template = template_selector.select_template(classification_result, preferred_format=preferred_format)
            print(f"âœ… íŒŒì¼ ì‹œìŠ¤í…œ ê¸°ë³¸ í…œí”Œë¦¿ ì„ íƒ: {template.template_type} ({template.template_id}, í˜•ì‹: {template.template_format})")

        # ë¶„ë¥˜ ê²°ê³¼ë¥¼ extracted_dataì— í¬í•¨ (Generator Guardìš©)
        extracted_data_with_classification = extracted_data.copy()
        extracted_data_with_classification["classification"] = classification
        
        # í…œí”Œë¦¿ í˜•ì‹ì— ë”°ë¼ ë‹¤ë¥¸ ì²˜ë¦¬
        template_format = template.template_format or "md"
        
        if template_format == "hwpx":
            # HWPX í…œí”Œë¦¿ ì²˜ë¦¬ (Windows ì „ìš©, ë„ì»¤ì—ì„œëŠ” ì‚¬ìš© ë¶ˆê°€)
            try:
                from pathlib import Path
                from app.utils.hwpx_template_handler import fill_hwpx_template
                from app.tools.field_mapper import get_field_mapper
                
                field_mapper = get_field_mapper()
                mapped_data = field_mapper.map_extracted_to_template(
                    extracted_data_with_classification,
                    []  # HWPXëŠ” íŒŒë€ìƒ‰ í…ìŠ¤íŠ¸ì—ì„œ í•„ë“œ ì¶”ì¶œ
                )
                
                # HWPX í…œí”Œë¦¿ì— ë°ì´í„° ì±„ìš°ê¸°
                template_path = Path(template.template_path)
                hwpx_bytes = fill_hwpx_template(template_path, mapped_data)
                
                # ë°”ì´íŠ¸ë¥¼ base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ ë¬¸ìì—´ë¡œ ë°˜í™˜ (ì„ì‹œ)
                import base64
                generated_document = base64.b64encode(hwpx_bytes).decode('utf-8')
            except (ImportError, ModuleNotFoundError):
                # pyhwpxê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì€ ê²½ìš° (ë„ì»¤ í™˜ê²½) ë§ˆí¬ë‹¤ìš´ í…œí”Œë¦¿ìœ¼ë¡œ í´ë°±
                print("âš ï¸ HWPX í…œí”Œë¦¿ ì‚¬ìš© ë¶ˆê°€ (pyhwpx ë¯¸ì„¤ì¹˜). ë§ˆí¬ë‹¤ìš´ í…œí”Œë¦¿ìœ¼ë¡œ í´ë°±í•©ë‹ˆë‹¤.")
                template_format = "md"
                # ì•„ë˜ ë§ˆí¬ë‹¤ìš´ ì²˜ë¦¬ ë¡œì§ìœ¼ë¡œ ì§„í–‰
            
        elif template_format == "pdf":
            # PDF í…œí”Œë¦¿ ì²˜ë¦¬
            from pathlib import Path
            from app.utils.pdf_template_handler import fill_pdf_template
            from app.tools.field_mapper import get_field_mapper
            
            field_mapper = get_field_mapper()
            mapped_data = field_mapper.map_extracted_to_template(
                extracted_data_with_classification,
                []  # PDFëŠ” íŒŒë€ìƒ‰ í…ìŠ¤íŠ¸ì—ì„œ í•„ë“œ ì¶”ì¶œ
            )
            
            # PDF í…œí”Œë¦¿ì— ë°ì´í„° ì±„ìš°ê¸°
            template_path = Path(template.template_path)
            pdf_bytes = fill_pdf_template(template_path, mapped_data)
            
            # ë°”ì´íŠ¸ë¥¼ base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ ë¬¸ìì—´ë¡œ ë°˜í™˜ (ì„ì‹œ)
            import base64
            generated_document = base64.b64encode(pdf_bytes).decode('utf-8')
            
        else:
            # ============================================================
            # STEP 4: Document Assembly (Non-LLM Pipeline ë‹¨ê³„)
            # ============================================================
            # í•µì‹¬ ì›ì¹™: "LLMì€ íŒë‹¨ë§Œ, ë¬¸ì„œ ìƒì„±ì€ ì½”ë“œê°€ í•œë‹¤"
            #
            # ì´ ë‹¨ê³„ëŠ” LLM Taskê°€ ì•„ë‹ˆë¼ Pipeline ë‹¨ê³„ì…ë‹ˆë‹¤:
            # - í…œí”Œë¦¿ ë Œë”ë§: field_mapperê°€ ëª¨ë“  í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ì±„ì›€
            # - ë°ì´í„° ë³€í™˜: extracted_data â†’ í…œí”Œë¦¿ í•„ë“œ ë§¤í•‘
            # - íŒŒìƒ í•„ë“œ ìƒì„±: ë‚ ì§œ ê³„ì‚°, ë²•ë ¹ ë¬¸êµ¬ ìƒì„± ë“±
            #
            # Generator AgentëŠ” ì„ íƒì  ê²€ì¦/ë‹¤ë“¬ê¸° ìš©ë„ë¡œë§Œ ì‚¬ìš© ê°€ëŠ¥
            # (ê¸°ë³¸ê°’: false - ì‚¬ìš© ì•ˆ í•¨)
            # ============================================================
            
            field_mapper = get_field_mapper()
            
            # í…œí”Œë¦¿ì— ë°ì´í„° ì±„ìš°ê¸° (Document Assembly)
            print("ğŸ“ Document Assembly ì‹œì‘: í…œí”Œë¦¿ ë Œë”ë§ ì¤‘...")
            filled_template = field_mapper.fill_template(
                template.content,
                extracted_data_with_classification
            )
            
            # í”Œë ˆì´ìŠ¤í™€ë” ê²€ì¦: ë‚¨ì€ í”Œë ˆì´ìŠ¤í™€ë” í™•ì¸
            import re
            remaining_placeholders = re.findall(r'\{([a-zA-Z_][a-zA-Z0-9_]*)\}', filled_template)
            if remaining_placeholders:
                print(f"âš ï¸ ê²½ê³ : ë‹¤ìŒ í”Œë ˆì´ìŠ¤í™€ë”ê°€ ì±„ì›Œì§€ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {set(remaining_placeholders)}")
                # ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ìš°ê¸° ì‹œë„
                default_values = {
                    "qualification_review_target": "ì ê²©ì‹¬ì‚¬ ì œì™¸ëŒ€ìƒì…ë‹ˆë‹¤.",
                    "integrity_pledge_target": "ì²­ë ´ê³„ì•½ì´í–‰ ì„œì•½ì œ ëŒ€ìƒì…ë‹ˆë‹¤.",
                    "contract_method_detail": "ì¼ë°˜ê²½ìŸ(ì´ì•¡), ì „ìì…ì°°ëŒ€ìƒ ë¬¼í’ˆì…ë‹ˆë‹¤.",
                }
                for placeholder in set(remaining_placeholders):
                    if placeholder in default_values:
                        filled_template = filled_template.replace(
                            f"{{{placeholder}}}",
                            default_values[placeholder]
                        )
                        print(f"âœ… í”Œë ˆì´ìŠ¤í™€ë” {placeholder}ì— ê¸°ë³¸ê°’ ì ìš©")
                # ë‚¨ì€ í”Œë ˆì´ìŠ¤í™€ë” ì¬í™•ì¸
                remaining_placeholders = re.findall(r'\{([a-zA-Z_][a-zA-Z0-9_]*)\}', filled_template)
                if remaining_placeholders:
                    print(f"âš ï¸ ì—¬ì „íˆ ì±„ì›Œì§€ì§€ ì•Šì€ í”Œë ˆì´ìŠ¤í™€ë”: {set(remaining_placeholders)}")
            else:
                print("âœ… ëª¨ë“  í”Œë ˆì´ìŠ¤í™€ë”ê°€ ì±„ì›Œì¡ŒìŠµë‹ˆë‹¤.")

            # ============================================================
            # ì„ íƒì : Generator Agent (LLM ê¸°ë°˜ ê²€ì¦/ë‹¤ë“¬ê¸°)
            # ============================================================
            # ê¸°ë³¸ê°’: false (ì‚¬ìš© ì•ˆ í•¨)
            #
            # Generator Agentì˜ ì—­í• :
            # - âŒ ë¬¸ì„œ ìƒì„± (ì´ë¯¸ field_mapperê°€ ì™„ë£Œ)
            # - âœ… ì„ íƒì  ê²€ì¦: í•„ìˆ˜ ìŠ¬ë¡¯ ëˆ„ë½ ì—¬ë¶€, ë¬¸ë§¥ ê²€ì¦
            # - âœ… ì„ íƒì  ë‹¤ë“¬ê¸°: ë¬¸ì¥ íë¦„ ê°œì„  (ìœ„í—˜: í…œí”Œë¦¿ ìˆ˜ì • ê°€ëŠ¥)
            #
            # ì‚¬ìš© ì¡°ê±´:
            # - í…œí”Œë¦¿ì— ë¹„ì–´ ìˆëŠ” ë¬¸ì¥ êµ¬ì¡°ê°€ ìˆëŠ” ê²½ìš°
            # - {}ë¡œ í‘œí˜„ë˜ì§€ ì•Šì€ ë¶€ë¶„ì„ LLMì´ ë¬¸ë§¥ìƒ ë§Œë“¤ì–´ì•¼ í•˜ëŠ” ê²½ìš°
            # - í˜„ì¬ í…œí”Œë¦¿ì€ ëª¨ë“  ê°€ë³€ ì •ë³´ê°€ {}ë¡œ ëª…ì‹œë˜ì–´ ìˆìœ¼ë¯€ë¡œ ë¶ˆí•„ìš”
            #
            # í™œì„±í™” ë°©ë²•:
            # 1. í™˜ê²½ ë³€ìˆ˜: USE_GENERATOR_AGENT=true
            # 2. docker-compose.yml: - USE_GENERATOR_AGENT=true
            #
            # ì£¼ì˜: Generator Agent ì‚¬ìš© ì‹œ í…œí”Œë¦¿ì´ ì˜ë¦¬ê±°ë‚˜ ìˆ˜ì •ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ
            #       ì˜ë¦¼ ê°ì§€ ë¡œì§ì´ ìë™ìœ¼ë¡œ filled_templateë¥¼ fallbackìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
            # ============================================================
            use_generator_agent = os.getenv("USE_GENERATOR_AGENT", "false").lower() == "true"
            
            if use_generator_agent:
                print("âš ï¸ Generator Agent ì‚¬ìš© ì¤‘ (ì„ íƒì  ê²€ì¦/ë‹¤ë“¬ê¸° ëª¨ë“œ)")
                # Generatorê°€ ë¬¸ì„œ ê²€ì¦/ë‹¤ë“¬ê¸° (ë¬¸ì¥ ë‹¤ë“¬ê¸° í¬í•¨)
                generation_task = create_generation_task(
                    self.generator,
                    filled_template,  # ì´ë¯¸ ì±„ì›Œì§„ í…œí”Œë¦¿
                    extracted_data_with_classification,
                    classification  # Rule Engine ê²°ì •ê°’ (ê°€ë“œìš©)
                )

                # Generatorë§Œ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ë¬¸ì„œ ê²€ì¦/ë‹¤ë“¬ê¸°
                generation_crew = Crew(
                    agents=[self.generator],
                    tasks=[generation_task],
                    process=Process.sequential,
                    verbose=True
                )
                
                generation_result = generation_crew.kickoff()
                generated_document = str(generation_result)
            else:
                # Generator Agent ê±´ë„ˆë›°ê¸°: field_mapper ê²°ê³¼ë¥¼ ë°”ë¡œ ì‚¬ìš© (ê¸°ë³¸ ë™ì‘)
                # field_mapperê°€ ì´ë¯¸ ëª¨ë“  í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ì±„ì› ìœ¼ë¯€ë¡œ ì¶”ê°€ LLM í˜¸ì¶œ ë¶ˆí•„ìš”
                print("âœ… Document Assembly ì™„ë£Œ: field_mapper ê²°ê³¼ë¥¼ ë°”ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                print("   (Generator AgentëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ - USE_GENERATOR_AGENT=false)")
                generated_document = filled_template
            
            # ì‘ë‹µì´ ì˜ë ¸ëŠ”ì§€ í™•ì¸ (í…œí”Œë¦¿ì˜ ì£¼ìš” ì„¹ì…˜ í¬í•¨ ì—¬ë¶€)
            template_sections = [
                "ê²¬ì (ì…ì°°)ì— ë¶€ì¹˜ëŠ” ì‚¬í•­", "ê²¬ì (ì…ì°°) ë° ê³„ì•½ë°©ì‹", "ì…ì°°ì°¸ê°€ìê²©", 
                "ê³µë™ê³„ì•½", "ì˜ˆì •ê°€ê²©", "ì²­ë ´ê³„ì•½ì´í–‰", "ì…ì°°ë³´ì¦ê¸ˆ", 
                "ì…ì°°ë¬´íš¨", "í•˜ë„ê¸‰", "ê¸°íƒ€ì‚¬í•­", "ìœ„ì™€ ê°™ì´ ê³µê³ í•©ë‹ˆë‹¤"
            ]
            missing_sections = []
            for section in template_sections:
                if section not in generated_document:
                    missing_sections.append(section)
            
            # ì„¹ì…˜ ë²ˆí˜¸ í™•ì¸ (1~10ê¹Œì§€ ëª¨ë‘ ìˆì–´ì•¼ í•¨)
            section_numbers = []
            for i in range(1, 11):
                if f"## {i}." in generated_document or f"## {i}." in filled_template:
                    section_numbers.append(i)
            
            # í…œí”Œë¦¿ ê¸¸ì´ ëŒ€ë¹„ ìƒì„± ë¬¸ì„œ ê¸¸ì´ í™•ì¸ (80% ë¯¸ë§Œì´ë©´ ì˜ë¦¼ìœ¼ë¡œ ê°„ì£¼)
            template_length = len(filled_template)
            generated_length = len(generated_document)
            length_ratio = generated_length / template_length if template_length > 0 else 0
            
            # ë¬¸ì„œê°€ ì˜ë ¸ëŠ”ì§€ í™•ì¸
            is_truncated = False
            if missing_sections:
                print(f"âš ï¸ ê²½ê³ : ìƒì„±ëœ ë¬¸ì„œì—ì„œ ë‹¤ìŒ ì„¹ì…˜ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_sections}")
                is_truncated = True
            
            if length_ratio < 0.8:
                print(f"âš ï¸ ê²½ê³ : ë¬¸ì„œê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ (í…œí”Œë¦¿: {template_length}ì, ìƒì„±: {generated_length}ì, ë¹„ìœ¨: {length_ratio:.2%}). LLM ì‘ë‹µì´ ì˜ë ¸ì„ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.")
                is_truncated = True
            
            # "ìœ„ì™€ ê°™ì´ ê³µê³ í•©ë‹ˆë‹¤"ê°€ ì—†ìœ¼ë©´ ì˜ë¦¼ìœ¼ë¡œ ê°„ì£¼
            if "ìœ„ì™€ ê°™ì´ ê³µê³ í•©ë‹ˆë‹¤" not in generated_document:
                print("âš ï¸ ê²½ê³ : ë¬¸ì„œ ëë¶€ë¶„ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤ ('ìœ„ì™€ ê°™ì´ ê³µê³ í•©ë‹ˆë‹¤' ì—†ìŒ).")
                is_truncated = True
            
            # ì˜ë ¸ìœ¼ë©´ filled_templateë¥¼ fallbackìœ¼ë¡œ ì‚¬ìš©
            if is_truncated and use_generator_agent:
                print("âš ï¸ Generator ì‘ë‹µì´ ë¶ˆì™„ì „í•©ë‹ˆë‹¤. field_mapper ê²°ê³¼ë¥¼ fallbackìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                generated_document = filled_template
            
            # Validator Agent ì‚¬ìš© ì—¬ë¶€ í™•ì¸ (í™˜ê²½ ë³€ìˆ˜ë¡œ ì œì–´, ê¸°ë³¸ê°’: true - ë©€í‹° ì—ì´ì „íŠ¸ ì‚¬ìš©)
            use_validator_agent = os.getenv("USE_VALIDATOR_AGENT", "true").lower() == "true"
            
            if use_validator_agent:
                # Generator ê²°ê³¼ë¥¼ Validatorê°€ ê²€í†  (ë©€í‹° ì—ì´ì „íŠ¸ í˜‘ì—…)
                # ë²•ë ¹ ì°¸ì¡°ëŠ” íŒŒë¼ë¯¸í„°ë¡œ ì „ë‹¬ë°›ìŒ
                
                validation_task = create_validation_task(
                    self.validator,
                    generated_document,  # Generatorê°€ ìƒì„±í•œ ë¬¸ì„œ
                    law_references
                )
                
                # Validatorê°€ Generator ê²°ê³¼ë¥¼ ê²€í† 
                validation_crew = Crew(
                    agents=[self.validator],
                    tasks=[validation_task],
                    process=Process.sequential,
                    verbose=True
                )
                
                validation_result = validation_crew.kickoff()
                
                # ê²€ì¦ ê²°ê³¼ í™•ì¸
                try:
                    validation_data = json.loads(str(validation_result))
                    issues = validation_data.get("issues", [])
                    
                    if issues:
                        print(f"âš ï¸ Validatorê°€ {len(issues)}ê°œ ì´ìŠˆ ë°œê²¬:")
                        for issue in issues[:3]:  # ìµœëŒ€ 3ê°œë§Œ ì¶œë ¥
                            print(f"  - {issue.get('issue_type', 'N/A')}: {issue.get('suggestion', 'N/A')}")
                    else:
                        print("âœ… Validator ê²€ì¦ í†µê³¼")
                        
                except json.JSONDecodeError:
                    print("âš ï¸ Validator ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨ (ë¬¸ì„œëŠ” ìƒì„±ë¨)")
            else:
                print("âœ… Validator Agent ê±´ë„ˆë›°ê¸°: ê²€ì¦ ë‹¨ê³„ë¥¼ ìƒëµí•©ë‹ˆë‹¤.")
            
            # ìµœì¢… ë¬¸ì„œëŠ” Generator ê²°ê³¼ ì‚¬ìš©
            generated_document = generated_document
            
            # [ì‹ ê·œ] Generator ì…€í”„ ë¦¬í”Œë ‰ì…˜ (ì œí•œì  ì‚¬ì „ ì ê²€)
            use_self_reflection = os.getenv("USE_SELF_REFLECTION", "true").lower() == "true"
            MAX_SELF_REFLECTION_ROUNDS = 1  # ë¬´í•œ ë£¨í”„ ë°©ì§€
            
            if use_self_reflection:
                print("\n" + "="*60)
                print("ğŸ” [ì…€í”„ ë¦¬í”Œë ‰ì…˜] Generator ì…€í”„ ë¦¬í”Œë ‰ì…˜ ì‹œì‘ (ì œí•œì  ì‚¬ì „ ì ê²€)")
                print("="*60)
                print(f"ğŸ“„ ë¬¸ì„œ ê¸¸ì´: {len(generated_document)}ì")
                print(f"ğŸ“‹ ë¶„ë¥˜ ê²°ê³¼: {classification.get('recommended_type', 'N/A')}")
                
                self_reflection_result = self.run_self_reflection(
                    generated_document,
                    extracted_data_with_classification,
                    classification,
                    round_count=0,
                    max_rounds=MAX_SELF_REFLECTION_ROUNDS
                )
                
                # ì…€í”„ ë¦¬í”Œë ‰ì…˜ ê²°ê³¼ ìƒì„¸ ë¡œê·¸
                print("\nğŸ“Š [ì…€í”„ ë¦¬í”Œë ‰ì…˜] ê²°ê³¼ ë¶„ì„:")
                self_check_passed = self_reflection_result.get("self_check_passed", True)
                issues = self_reflection_result.get("issues", [])
                auto_fixable = self_reflection_result.get("auto_fixable", {})
                
                if self_check_passed:
                    print("âœ… ì…€í”„ ë¦¬í”Œë ‰ì…˜ í†µê³¼: ë¬¸ì œ ì—†ìŒ")
                else:
                    print(f"âš ï¸ ì…€í”„ ë¦¬í”Œë ‰ì…˜ì—ì„œ {len(issues)}ê°œ ì´ìŠˆ ë°œê²¬:")
                    for idx, issue in enumerate(issues, 1):
                        issue_type = issue.get('type', 'N/A')
                        description = issue.get('description', 'N/A')
                        confidence = issue.get('confidence', 'N/A')
                        fix_type = issue.get('fix_type', 'N/A')
                        location = issue.get('location', 'N/A')
                        patch = issue.get('patch', {})
                        
                        print(f"\n  [{idx}] ì´ìŠˆ ìƒì„¸:")
                        print(f"      - ìœ í˜•: {issue_type}")
                        print(f"      - ì„¤ëª…: {description}")
                        print(f"      - ì‹ ë¢°ë„: {confidence}")
                        print(f"      - ìˆ˜ì • ìœ í˜•: {fix_type}")
                        print(f"      - ìœ„ì¹˜: {location}")
                        if patch:
                            print(f"      - íŒ¨ì¹˜: {patch.get('action', 'N/A')} '{patch.get('target', 'N/A')}' â†’ '{patch.get('value', 'N/A')}'")
                    
                    # ìë™ ìˆ˜ì • ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
                    if auto_fixable.get("allowed", False):
                        fix_scope = auto_fixable.get("fix_scope", "none")
                        print(f"\nğŸ”§ [ìë™ ìˆ˜ì •] ìë™ ìˆ˜ì • ê°€ëŠ¥ (ë²”ìœ„: {fix_scope})")
                        
                        if fix_scope in ["placeholder_only", "section_header_only"]:
                            print(f"   ì ìš© ì¤‘...")
                            original_doc_length = len(generated_document)
                            generated_document = self.apply_self_reflection_fixes(
                                generated_document,
                                issues,
                                fix_scope
                            )
                            fixed_doc_length = len(generated_document)
                            print(f"   âœ… ìë™ ìˆ˜ì • ì™„ë£Œ (ë¬¸ì„œ ê¸¸ì´: {original_doc_length}ì â†’ {fixed_doc_length}ì)")
                        else:
                            print(f"   âš ï¸ ìë™ ìˆ˜ì • ë²”ìœ„ê°€ ì•ˆì „í•˜ì§€ ì•Šì•„ ê±´ë„ˆëœë‹ˆë‹¤. (fix_scope: {fix_scope})")
                    else:
                        print(f"\nâš ï¸ [ìë™ ìˆ˜ì •] ìë™ ìˆ˜ì • ë¶ˆê°€ëŠ¥í•œ ì´ìŠˆì…ë‹ˆë‹¤.")
                        print(f"   Validatorë¡œ ì „ë‹¬ë©ë‹ˆë‹¤.")
                
                print("="*60 + "\n")
            else:
                print("â­ï¸  [ì…€í”„ ë¦¬í”Œë ‰ì…˜] ê±´ë„ˆë›°ê¸°: USE_SELF_REFLECTION=false")

        # Generator ê²°ê³¼ ê²€ì¦ (Rule Guard)
        validation_issues = self._validate_generation_result(
            generated_document,
            classification
        )
        
        if validation_issues:
            print(f"âš ï¸ Generator ê²°ê³¼ ê²€ì¦ ì´ìŠˆ ë°œê²¬: {len(validation_issues)}ê°œ")
            for issue in validation_issues:
                print(f"  - {issue.get('issue_type')}: {issue.get('suggestion')}")

        # AgentState ì—…ë°ì´íŠ¸
        self.state.generated_document = generated_document
        self.state.transition_to("validate")

        return generated_document
    
    def _validate_generation_result(
        self,
        generated_document: str,
        classification: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        ìƒì„±ëœ ë¬¸ì„œê°€ ë¶„ë¥˜ ê²°ì •ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€ì¦ (Rule Guard)
        
        Args:
            generated_document: ìƒì„±ëœ ê³µê³ ë¬¸
            classification: ë¶„ë¥˜ ê²°ê³¼
            
        Returns:
            ê²€ì¦ ì´ìŠˆ ëª©ë¡
        """
        issues = []
        recommended_type = classification.get("recommended_type", "")
        applied_annex = classification.get("applied_annex")
        sme_restriction = classification.get("sme_restriction", "")
        
        # ê³µê³  ë°©ì‹ ë¶ˆì¼ì¹˜ ê²€ì‚¬
        if recommended_type == "ì ê²©ì‹¬ì‚¬":
            if "ì†Œì•¡ìˆ˜ì˜" in generated_document or "ì†Œì•¡" in generated_document:
                issues.append({
                    "issue_type": "ë¶„ë¥˜ ê²°ì • ë¶ˆì¼ì¹˜",
                    "severity": "high",
                    "current_text": "ì†Œì•¡ìˆ˜ì˜ ê´€ë ¨ í‘œí˜„ ë°œê²¬",
                    "suggestion": f"ê³µê³  ë°©ì‹ì´ Rule Engine ê²°ì •({recommended_type})ê³¼ ë‹¤ë¦…ë‹ˆë‹¤. 'ì ê²©ì‹¬ì‚¬' í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”."
                })
        elif recommended_type == "ì†Œì•¡ìˆ˜ì˜":
            if "ì ê²©ì‹¬ì‚¬" in generated_document:
                issues.append({
                    "issue_type": "ë¶„ë¥˜ ê²°ì • ë¶ˆì¼ì¹˜",
                    "severity": "high",
                    "current_text": "ì ê²©ì‹¬ì‚¬ ê´€ë ¨ í‘œí˜„ ë°œê²¬",
                    "suggestion": f"ê³µê³  ë°©ì‹ì´ Rule Engine ê²°ì •({recommended_type})ê³¼ ë‹¤ë¦…ë‹ˆë‹¤. 'ì†Œì•¡ìˆ˜ì˜' í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”."
                })
        
        # ë³„í‘œ ë¶ˆì¼ì¹˜ ê²€ì‚¬
        if applied_annex:
            if applied_annex not in generated_document:
                issues.append({
                    "issue_type": "ë³„í‘œ ëˆ„ë½",
                    "severity": "medium",
                    "suggestion": f"ì ìš© ë³„í‘œ({applied_annex})ê°€ ë¬¸ì„œì— ëª…ì‹œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                })
        
        return issues

    def run_self_reflection(
        self,
        generated_document: str,
        extracted_data: Dict[str, Any],
        classification: Dict[str, Any],
        round_count: int = 0,
        max_rounds: int = 1
    ) -> Dict[str, Any]:
        """
        Generator ì…€í”„ ë¦¬í”Œë ‰ì…˜ (ì œí•œì  ì‚¬ì „ ì ê²€)
        
        Generatorê°€ ìì‹ ì˜ ì¶œë ¥ì„ ì œí•œì ìœ¼ë¡œ ê²€í† í•©ë‹ˆë‹¤.
        - í•„ìˆ˜ ì„¹ì…˜ ëˆ„ë½ ì—¬ë¶€
        - í”Œë ˆì´ìŠ¤í™€ë” ë‚¨ì•„ìˆìŒ ì—¬ë¶€
        - ë¶„ë¥˜ ê²°ê³¼ì™€ ì¼ì¹˜ ì—¬ë¶€
        - ê¸°ë³¸ êµ¬ì¡° ì •í™•ì„±
        
        âš ï¸ ë¬´í•œ ë£¨í”„ ë°©ì§€: ìµœëŒ€ 1íšŒë§Œ ì‹¤í–‰
        
        Args:
            generated_document: Generatorê°€ ìƒì„±í•œ ë¬¸ì„œ
            extracted_data: ì¶”ì¶œëœ ë°ì´í„°
            classification: ë¶„ë¥˜ ê²°ê³¼
            round_count: í˜„ì¬ ë¼ìš´ë“œ (ë¬´í•œ ë£¨í”„ ë°©ì§€ìš©)
            max_rounds: ìµœëŒ€ ë¼ìš´ë“œ ìˆ˜ (ê¸°ë³¸ê°’: 1)
        
        Returns:
            SelfReflectionResult í˜•ì‹ì˜ ë”•ì…”ë„ˆë¦¬
        """
        # ë¬´í•œ ë£¨í”„ ë°©ì§€
        if round_count >= max_rounds:
            logger.debug(f"âš ï¸ ì…€í”„ ë¦¬í”Œë ‰ì…˜ ìµœëŒ€ ë¼ìš´ë“œ({max_rounds}) ë„ë‹¬. ê±´ë„ˆëœë‹ˆë‹¤.")
            return {
                "self_check_passed": True,
                "issues": [],
                "auto_fixable": {"allowed": False, "fix_scope": "none"}
            }
        
        print(f"   ğŸ“ [ì…€í”„ ë¦¬í”Œë ‰ì…˜] Task ìƒì„± ì¤‘...")
        task = create_self_reflection_task(
            self.generator,
            generated_document,
            extracted_data,
            classification
        )
        
        print(f"   ğŸ¤– [ì…€í”„ ë¦¬í”Œë ‰ì…˜] Generator Agent ì‹¤í–‰ ì¤‘...")
        crew = Crew(
            agents=[self.generator],
            tasks=[task],
            process=Process.sequential,
            verbose=True
        )
        
        result = crew.kickoff()
        print(f"   âœ… [ì…€í”„ ë¦¬í”Œë ‰ì…˜] Generator Agent ì‹¤í–‰ ì™„ë£Œ")
        
        print(f"   ğŸ” [ì…€í”„ ë¦¬í”Œë ‰ì…˜] ê²°ê³¼ íŒŒì‹± ì¤‘...")
        try:
            reflection_result = json.loads(str(result))
            print(f"   âœ… [ì…€í”„ ë¦¬í”Œë ‰ì…˜] JSON íŒŒì‹± ì„±ê³µ")
        except json.JSONDecodeError:
            print(f"   âš ï¸ [ì…€í”„ ë¦¬í”Œë ‰ì…˜] JSON íŒŒì‹± ì‹¤íŒ¨, ì½”ë“œ ë¸”ë¡ì—ì„œ ì¶”ì¶œ ì‹œë„...")
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            import re
            result_str = str(result)
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', result_str, re.DOTALL)
            if json_match:
                try:
                    reflection_result = json.loads(json_match.group(1))
                    print(f"   âœ… [ì…€í”„ ë¦¬í”Œë ‰ì…˜] ì½”ë“œ ë¸”ë¡ì—ì„œ JSON ì¶”ì¶œ ì„±ê³µ")
                except json.JSONDecodeError:
                    print(f"   âŒ [ì…€í”„ ë¦¬í”Œë ‰ì…˜] ì½”ë“œ ë¸”ë¡ JSON íŒŒì‹±ë„ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©")
                    reflection_result = {
                        "self_check_passed": True,
                        "issues": [],
                        "auto_fixable": {"allowed": False, "fix_scope": "none"},
                        "raw_output": result_str
                    }
            else:
                print(f"   âŒ [ì…€í”„ ë¦¬í”Œë ‰ì…˜] JSON ì½”ë“œ ë¸”ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ, ê¸°ë³¸ê°’ ì‚¬ìš©")
                reflection_result = {
                    "self_check_passed": True,
                    "issues": [],
                    "auto_fixable": {"allowed": False, "fix_scope": "none"},
                    "raw_output": result_str
                }
        
        # ê¸°ë³¸ê°’ ë³´ì¥
        if "self_check_passed" not in reflection_result:
            reflection_result["self_check_passed"] = len(reflection_result.get("issues", [])) == 0
        
        if "auto_fixable" not in reflection_result:
            reflection_result["auto_fixable"] = {"allowed": False, "fix_scope": "none"}
        
        # ê²°ê³¼ ìš”ì•½ ë¡œê·¸
        issues_count = len(reflection_result.get("issues", []))
        print(f"   ğŸ“Š [ì…€í”„ ë¦¬í”Œë ‰ì…˜] ê²°ê³¼ ìš”ì•½:")
        print(f"      - í†µê³¼ ì—¬ë¶€: {'âœ… í†µê³¼' if reflection_result.get('self_check_passed') else 'âŒ ì‹¤íŒ¨'}")
        print(f"      - ë°œê²¬ëœ ì´ìŠˆ: {issues_count}ê°œ")
        print(f"      - ìë™ ìˆ˜ì • ê°€ëŠ¥: {'âœ… ê°€ëŠ¥' if reflection_result.get('auto_fixable', {}).get('allowed') else 'âŒ ë¶ˆê°€ëŠ¥'}")
        if reflection_result.get('auto_fixable', {}).get('allowed'):
            print(f"      - ìˆ˜ì • ë²”ìœ„: {reflection_result.get('auto_fixable', {}).get('fix_scope', 'N/A')}")
        
        return reflection_result
    
    def apply_self_reflection_fixes(
        self,
        document: str,
        issues: List[Dict[str, Any]],
        fix_scope: str
    ) -> str:
        """
        ì…€í”„ ë¦¬í”Œë ‰ì…˜ì—ì„œ ë°œê²¬ëœ ì´ìŠˆë¥¼ ìë™ìœ¼ë¡œ ìˆ˜ì •
        
        âš ï¸ ì•ˆì „í•œ ìˆ˜ì •ë§Œ ìˆ˜í–‰:
        - placeholder_only: í”Œë ˆì´ìŠ¤í™€ë”ë§Œ ìˆ˜ì •
        - section_header_only: ì„¹ì…˜ í—¤ë”ë§Œ ìˆ˜ì •
        
        Args:
            document: ì›ë³¸ ë¬¸ì„œ
            issues: ì…€í”„ ë¦¬í”Œë ‰ì…˜ ì´ìŠˆ ëª©ë¡
            fix_scope: ìˆ˜ì • ë²”ìœ„
        
        Returns:
            ìˆ˜ì •ëœ ë¬¸ì„œ
        """
        import re
        
        print(f"      ğŸ”§ [ìë™ ìˆ˜ì •] ìˆ˜ì • ë²”ìœ„: {fix_scope}")
        fixed_document = document
        fix_count = 0
        
        # ì•ˆì „í•œ ìˆ˜ì •ë§Œ ìˆ˜í–‰
        safe_types = {
            "placeholder_only": ["placeholder_remaining"],
            "section_header_only": ["missing_section", "structure_error"]
        }
        
        allowed_types = safe_types.get(fix_scope, [])
        print(f"      ğŸ“‹ [ìë™ ìˆ˜ì •] í—ˆìš©ëœ ì´ìŠˆ ìœ í˜•: {allowed_types}")
        
        for idx, issue in enumerate(issues, 1):
            issue_type = issue.get("type", "")
            if issue_type not in allowed_types:
                print(f"      â­ï¸  [{idx}] ì´ìŠˆ ìœ í˜• '{issue_type}'ëŠ” ìˆ˜ì • ë²”ìœ„ì— ì—†ì–´ ê±´ë„ˆëœ€")
                continue
            
            patch = issue.get("patch", {})
            if not patch:
                print(f"      âš ï¸  [{idx}] íŒ¨ì¹˜ ì •ë³´ê°€ ì—†ì–´ ê±´ë„ˆëœ€")
                continue
            
            action = patch.get("action", "")
            target = patch.get("target", "")
            value = patch.get("value", "")
            
            print(f"      ğŸ”¨ [{idx}] ìˆ˜ì • ì ìš©: {action} '{target}' â†’ '{value}'")
            
            if action == "replace" and target and value:
                # í”Œë ˆì´ìŠ¤í™€ë” êµì²´
                if issue_type == "placeholder_remaining":
                    # {placeholder} í˜•ì‹ ì°¾ì•„ì„œ êµì²´
                    placeholder_pattern = re.escape(target)
                    before_count = fixed_document.count(target)
                    fixed_document = re.sub(placeholder_pattern, value, fixed_document)
                    after_count = fixed_document.count(target)
                    replaced_count = before_count - after_count
                    if replaced_count > 0:
                        fix_count += replaced_count
                        print(f"         âœ… í”Œë ˆì´ìŠ¤í™€ë” êµì²´ ì™„ë£Œ: {target} â†’ {value} ({replaced_count}íšŒ)")
                    else:
                        print(f"         âš ï¸  í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {target}")
            
            elif action == "add" and target and value:
                # ì„¹ì…˜ ì¶”ê°€ (ì•ˆì „í•œ ê²½ìš°ë§Œ)
                if issue_type == "missing_section":
                    # ì„¹ì…˜ ìœ„ì¹˜ ì°¾ì•„ì„œ ì¶”ê°€
                    location = issue.get("location", "")
                    if location and value:
                        # ê°„ë‹¨í•œ ì¶”ê°€ ë¡œì§ (ë³µì¡í•œ ê²ƒì€ Validatorë¡œ)
                        if target in fixed_document:
                            fixed_document = fixed_document.replace(target, f"{target}\n{value}")
                            fix_count += 1
                            print(f"         âœ… ì„¹ì…˜ ì¶”ê°€ ì™„ë£Œ: {value}")
                        else:
                            print(f"         âš ï¸  íƒ€ê²Ÿ ìœ„ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {target}")
        
        print(f"      ğŸ“Š [ìë™ ìˆ˜ì •] ì´ {fix_count}ê°œ ìˆ˜ì • ì ìš© ì™„ë£Œ")
        return fixed_document

    def run_validation(
        self,
        generated_document: str,
        law_references: str
    ) -> Dict[str, Any]:
        """
        STEP 5: ë²•ë ¹ ê²€ì¦

        Returns:
            ValidationResult í˜•ì‹ì˜ ë”•ì…”ë„ˆë¦¬
        """
        task = create_validation_task(
            self.validator,
            generated_document,
            law_references
        )

        crew = Crew(
            agents=[self.validator],
            tasks=[task],
            process=Process.sequential,
            verbose=True
        )

        result = crew.kickoff()

        try:
            validation_result = json.loads(str(result))
        except json.JSONDecodeError:
            validation_result = {
                "is_valid": False,
                "issues": [],
                "checked_laws": [],
                "timestamp": datetime.now().isoformat(),
                "raw_output": str(result)
            }

        # AgentState ì—…ë°ì´íŠ¸
        self.state.validation_issues = validation_result.get("issues", [])

        return validation_result

    def run_revision(
        self,
        original_document: str,
        validation_issues: list
    ) -> str:
        """
        STEP 6: ê²€ì¦ ì´ìŠˆ ë°˜ì˜í•˜ì—¬ ìˆ˜ì •

        Returns:
            ìˆ˜ì •ëœ ê³µê³ ë¬¸ ë¬¸ìì—´
        """
        task = create_revision_task(
            self.generator,  # ìˆ˜ì •ë„ generatorê°€ ë‹´ë‹¹
            original_document,
            validation_issues
        )

        crew = Crew(
            agents=[self.generator],
            tasks=[task],
            process=Process.sequential,
            verbose=True
        )

        result = crew.kickoff()
        revised_document = str(result)
        
        # Revision ê²°ê³¼ ê²€ì¦: ì›ë³¸ ë¬¸ì„œ ê¸¸ì´ ëŒ€ë¹„ í™•ì¸
        original_length = len(original_document)
        revised_length = len(revised_document)
        length_ratio = revised_length / original_length if original_length > 0 else 0
        
        # í•„ìˆ˜ ì„¹ì…˜ í™•ì¸
        required_sections = [
            "ìœ„ì™€ ê°™ì´ ê³µê³ í•©ë‹ˆë‹¤",
            "ê¸°íƒ€ì‚¬í•­",
            "ì…ì°°ë¬´íš¨",
            "ì…ì°°ë³´ì¦ê¸ˆ",
            "ì²­ë ´ê³„ì•½ì´í–‰",
            "ì˜ˆì •ê°€ê²©",
            "ê³µë™ê³„ì•½",
            "ì…ì°°ì°¸ê°€ìê²©"
        ]
        missing_sections = [s for s in required_sections if s not in revised_document]
        
        # Revisionì´ ë¬¸ì„œë¥¼ ì˜ëëŠ”ì§€ í™•ì¸
        if length_ratio < 0.8 or missing_sections:
            print(f"âš ï¸ ê²½ê³ : Revision ê²°ê³¼ê°€ ë¶ˆì™„ì „í•©ë‹ˆë‹¤ (ì›ë³¸: {original_length}ì, ìˆ˜ì •: {revised_length}ì, ë¹„ìœ¨: {length_ratio:.2%})")
            if missing_sections:
                print(f"âš ï¸ ëˆ„ë½ëœ ì„¹ì…˜: {missing_sections}")
            print("âš ï¸ ì›ë³¸ ë¬¸ì„œë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.")
            return original_document
        
        print(f"âœ… Revision ì™„ë£Œ (ì›ë³¸: {original_length}ì, ìˆ˜ì •: {revised_length}ì, ë¹„ìœ¨: {length_ratio:.2%})")

        # AgentState ì—…ë°ì´íŠ¸
        self.state.generated_document = revised_document
        self.state.increment_retry()

        return revised_document

    def run_full_pipeline(
        self,
        document_text: str,
        law_references: str = "",
        max_iterations: int = 10,
        template_info: Dict[str, Any] = None
    ) -> str:
        """
        ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ - ì™„ë²½í•œ ë¬¸ì„œê°€ ë‚˜ì˜¬ ë•Œê¹Œì§€ ë°˜ë³µ

        Args:
            document_text: ì›ë³¸ ë¬¸ì„œ í…ìŠ¤íŠ¸
            law_references: ë²•ë ¹ ì°¸ì¡° í…ìŠ¤íŠ¸
            max_iterations: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ (ë¬´í•œ ë£¨í”„ ë°©ì§€)

        Returns:
            ì™„ì„±ëœ ê³µê³ ë¬¸ ë¬¸ìì—´ (String)
        """
        # STEP 1: ì¶”ì¶œ
        extracted_data = self.run_extraction(document_text)

        # STEP 2: ë¶„ë¥˜
        classification = self.run_classification(extracted_data)

        # ë¶„ë¥˜ ê²°ê³¼ ì¶œë ¥
        print(f"ğŸ“‹ ë¶„ë¥˜ ê²°ê³¼: {classification.get('recommended_type')}")

        # STEP 3: ìƒì„± (í…œí”Œë¦¿ + ë°ì´í„° ë§¤í•‘ ë°©ì‹)
        # ê³µê³  ë°©ì‹ìœ¼ë¡œ í…œí”Œë¦¿ ì„ íƒ
        announcement_type = classification.get("recommended_type")
        
        # ì†Œì•¡ìˆ˜ì˜ëŠ” "ìµœì €ê°€ë‚™ì°°" í…œí”Œë¦¿ ì‚¬ìš©
        if announcement_type == "ì†Œì•¡ìˆ˜ì˜":
            announcement_type = "ìµœì €ê°€ë‚™ì°°"
        
        current_document = self.run_generation(
            extracted_data,
            announcement_type=announcement_type,
            law_references=law_references,
            template_info=template_info
        )

        # ============================================================
        # STEP 4: ê²€ì¦ ë° ìˆ˜ì • (ë©€í‹° ì—ì´ì „íŠ¸ í˜‘ì—…)
        # ============================================================
        # Validator Agentì™€ Generator Agentê°€ í˜‘ì—…í•˜ì—¬ ë¬¸ì„œë¥¼ ê²€ì¦í•˜ê³  ìˆ˜ì •í•©ë‹ˆë‹¤.
        # - Validator: ë²•ë ¹ ê²€ì¦ ë° ì´ìŠˆ ë°œê²¬
        # - Generator: ë°œê²¬ëœ ì´ìŠˆ ë°˜ì˜í•˜ì—¬ ë¬¸ì„œ ìˆ˜ì •
        # ============================================================
        use_validator_agent = os.getenv("USE_VALIDATOR_AGENT", "true").lower() == "true"
        
        if use_validator_agent:
            # ê²€ì¦ ìˆ˜í–‰ (Validator Agent)
            validation_result = self.run_validation(
                current_document,
                law_references
            )
            
            issues = validation_result.get("issues", [])
            
            # High severity ì´ìŠˆë§Œ í•„í„°ë§
            high_severity_issues = [issue for issue in issues if issue.get("severity") == "high"]
            
            if high_severity_issues:
                print(f"âš ï¸ High severity ì´ìŠˆ {len(high_severity_issues)}ê°œ ë°œê²¬ (ì „ì²´ {len(issues)}ê°œ)")
                print("ğŸ”„ Generator Agentê°€ Validatorì˜ ì´ìŠˆë¥¼ ë°˜ì˜í•˜ì—¬ ë¬¸ì„œ ìˆ˜ì • ì¤‘... (ë©€í‹° ì—ì´ì „íŠ¸ í˜‘ì—…)")
                # High severity ì´ìŠˆë§Œ ìˆ˜ì • (Generator Agentê°€ Validator ê²°ê³¼ë¥¼ ë°›ì•„ì„œ ìˆ˜ì •)
                current_document = self.run_revision(
                    current_document,
                    high_severity_issues  # High severityë§Œ ì „ë‹¬
                )
            elif issues:
                print(f"â„¹ï¸ Medium/Low severity ì´ìŠˆ {len(issues)}ê°œ ë°œê²¬ (ë¬´ì‹œí•˜ê³  ì§„í–‰)")
            else:
                print("âœ… ê²€ì¦ ì™„ë£Œ: ì´ìŠˆ ì—†ìŒ")
        else:
            print("âœ… Validator Agent ê±´ë„ˆë›°ê¸°: ê²€ì¦ ë‹¨ê³„ë¥¼ ìƒëµí•©ë‹ˆë‹¤.")

        # ìµœëŒ€ ë°˜ë³µ ë„ë‹¬ - ìµœì„ ì˜ ê²°ê³¼ ë°˜í™˜
        print(f"âš ï¸ ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜({max_iterations})ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. í˜„ì¬ ë²„ì „ì„ ë°˜í™˜í•©ë‹ˆë‹¤.")
        self.state.transition_to("complete")
        return current_document
