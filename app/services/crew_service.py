from crewai import Crew, Process
from typing import Dict, Any, Optional, List
import json
import os
from datetime import datetime

from .agents import (
    create_extractor_agent,
    create_classifier_agent,
    create_generator_agent,
    create_validator_agent
)
from .tasks import (
    create_extraction_task,
    create_classification_task,
    create_generation_task,
    create_validation_task,
    create_revision_task
)
from app.models.agent_state import AgentState


class BiddingDocumentCrew:
    """
    ì…ì°° ê³µê³ ë¬¸ ìë™ ì‘ì„± Crew (ë©€í‹° ì—ì´ì „íŠ¸ êµ¬ì¡°)
    
    í˜„ì¬ êµ¬ì¡°: ìˆœì°¨ì  ë©€í‹° ì—ì´ì „íŠ¸
    - ê° ë‹¨ê³„ë§ˆë‹¤ ë³„ë„ì˜ Crew ìƒì„± (Extractor â†’ Classifier â†’ Generator â†’ Validator)
    - Agentë“¤ì´ ìˆœì°¨ì ìœ¼ë¡œ í˜‘ì—…í•˜ì—¬ ì „ì²´ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
    
    í–¥í›„ ê°œì„  ê°€ëŠ¥: í˜‘ì—…ì  ë©€í‹° ì—ì´ì „íŠ¸
    - ì—¬ëŸ¬ Agentê°€ í•œ Crewì— í•¨ê»˜ ìˆì–´ì„œ ë™ì‹œì— í˜‘ì—…
    - Task ê°„ ì˜ì¡´ì„± ì„¤ì •ìœ¼ë¡œ ë” ìœ ì—°í•œ í˜‘ì—… ê°€ëŠ¥
    """

    def __init__(self, state: AgentState):
        self.state = state
        self.extractor = create_extractor_agent()
        self.classifier = create_classifier_agent()
        self.generator = create_generator_agent()
        self.validator = create_validator_agent()

    def run_extraction(self, document_text: str) -> Dict[str, Any]:
        """
        STEP 2: ë¬¸ì„œì—ì„œ ì •ë³´ ì¶”ì¶œ

        Returns:
            ExtractedData í˜•ì‹ì˜ ë”•ì…”ë„ˆë¦¬
        """
        task = create_extraction_task(self.extractor, document_text)

        crew = Crew(
            agents=[self.extractor],
            tasks=[task],
            process=Process.sequential,
            verbose=True
        )

        result = crew.kickoff()

        # ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ íŒŒì‹±
        try:
            extracted_data = json.loads(str(result))
        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ raw_outputì—ì„œ JSON ì¶”ì¶œ ì‹œë„
            import re
            result_str = str(result)
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', result_str, re.DOTALL)
            if json_match:
                try:
                    extracted_data = json.loads(json_match.group(1))
                except json.JSONDecodeError:
                    extracted_data = {"raw_output": result_str}
            else:
                extracted_data = {"raw_output": result_str}

        # AgentState ì—…ë°ì´íŠ¸
        self.state.extracted_data = extracted_data
        self.state.transition_to("classify")

        return extracted_data

    def run_classification(self, extracted_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        STEP 3: ê³µê³  ìœ í˜• ë¶„ë¥˜ (Classifier Agent + Rule Engine Tool)
        
        Classifier Agentê°€ Rule Engine Toolì„ ì‚¬ìš©í•˜ì—¬ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        1ì°¨ ë¶„ê¸°: ê³µê³  ë°©ì‹ (ì†Œì•¡ìˆ˜ì˜/ì ê²©ì‹¬ì‚¬)
        2ì°¨ ë¶„ê¸°: ê³„ì•½ ì„±ê²© (êµ­ê°€ê³„ì•½/ë‹¨ê°€ê³„ì•½, ë‹¨ë…/ê³µë™)

        Returns:
            ClassificationResult í˜•ì‹ì˜ ë”•ì…”ë„ˆë¦¬
        """
        import json
        
        # Classifier Agentê°€ Rule Engine Toolì„ ì‚¬ìš©í•˜ë„ë¡ Task ìƒì„±
        task = create_classification_task(
            self.classifier,
            extracted_data
        )
        
        # Classifier Agentë§Œ ì‚¬ìš© (Rule Engineì€ Toolë¡œ ì œê³µ)
        crew = Crew(
            agents=[self.classifier],
            tasks=[task],
            process=Process.sequential,
            verbose=True
        )
        
        result = crew.kickoff()
        
        # ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ íŒŒì‹±
        try:
            classification = json.loads(str(result))
            
            # Agent ê²°ê³¼ ê²€ì¦: ê¸ˆì•¡ì´ 0ì´ë©´ fallback ì‚¬ìš©
            if classification.get("estimated_price_exc_vat") == 0 or classification.get("total_budget_vat") == 0:
                print("âš ï¸ Classifier Agent ê²°ê³¼ì— ê¸ˆì•¡ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. Rule Engine ì§ì ‘ í˜¸ì¶œ...")
                raise ValueError("Invalid classification result")
        except (json.JSONDecodeError, ValueError, KeyError) as e:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ë˜ëŠ” ìœ íš¨í•˜ì§€ ì•Šì€ ê²°ê³¼ ì‹œ Rule Engine ì§ì ‘ í˜¸ì¶œ (fallback)
            print(f"âš ï¸ Classifier Agent ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨ ë˜ëŠ” ìœ íš¨í•˜ì§€ ì•ŠìŒ: {e}. Rule Engine ì§ì ‘ í˜¸ì¶œ...")
            from app.tools.rule_engine import get_rule_engine
            from app.models.schemas import ExtractedData
            
            # extracted_dataì—ì„œ raw_output íŒŒì‹± ì‹œë„
            parsed_data = extracted_data.copy()
            if "raw_output" in extracted_data and isinstance(extracted_data["raw_output"], str):
                try:
                    # raw_outputì—ì„œ JSON ì¶”ì¶œ ì‹œë„
                    import re
                    json_match = re.search(r'```json\s*(\{.*?\})\s*```', extracted_data["raw_output"], re.DOTALL)
                    if json_match:
                        raw_json = json.loads(json_match.group(1))
                        # raw_jsonì˜ ê°’ìœ¼ë¡œ parsed_data ì—…ë°ì´íŠ¸ (ê¸°ì¡´ ê°’ì´ ì—†ì„ ë•Œë§Œ)
                        for key, value in raw_json.items():
                            if key not in parsed_data or not parsed_data[key]:
                                parsed_data[key] = value
                except Exception as parse_error:
                    print(f"âš ï¸ raw_output íŒŒì‹± ì‹¤íŒ¨: {parse_error}")
            
            # ë°ì´í„° íƒ€ì… ì •ê·œí™” (ExtractedData ìŠ¤í‚¤ë§ˆì— ë§ê²Œ)
            # qualification_notesê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
            if "qualification_notes" in parsed_data and isinstance(parsed_data["qualification_notes"], list):
                parsed_data["qualification_notes"] = "\n".join(str(item) for item in parsed_data["qualification_notes"])
            
            # detail_item_codesì™€ industry_codesê°€ ë¬¸ìì—´ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            if "detail_item_codes" in parsed_data:
                if isinstance(parsed_data["detail_item_codes"], str):
                    parsed_data["detail_item_codes"] = [parsed_data["detail_item_codes"]] if parsed_data["detail_item_codes"] else []
                elif parsed_data["detail_item_codes"] is None:
                    parsed_data["detail_item_codes"] = []
                    
            if "industry_codes" in parsed_data:
                if isinstance(parsed_data["industry_codes"], str):
                    parsed_data["industry_codes"] = [parsed_data["industry_codes"]] if parsed_data["industry_codes"] else []
                elif parsed_data["industry_codes"] is None:
                    parsed_data["industry_codes"] = []
            
            try:
                extracted_model = ExtractedData(**parsed_data)
            except Exception as e:
                print(f"âš ï¸ ExtractedData ë³€í™˜ ì‹¤íŒ¨: {e}")
                # ìµœì†Œí•œì˜ í•„ë“œë¡œ ExtractedData ìƒì„±
                extracted_model = ExtractedData(
                    procurement_type=parsed_data.get("procurement_type", "ë¬¼í’ˆ"),
                    total_budget_vat=parsed_data.get("total_budget_vat") or parsed_data.get("estimated_amount", 0),
                    estimated_amount=parsed_data.get("estimated_amount", 0),
                    item_name=parsed_data.get("item_name", ""),
                    project_name=parsed_data.get("project_name", ""),
                    delivery_deadline_days=parsed_data.get("delivery_deadline_days"),
                    procurement_method_raw=parsed_data.get("procurement_method_raw", ""),
                    detail_item_codes=parsed_data.get("detail_item_codes", []),
                    industry_codes=parsed_data.get("industry_codes", []),
                    is_joint_contract=parsed_data.get("is_joint_contract", False),
                    has_region_restriction=parsed_data.get("has_region_restriction", False),
                    qualification_notes=parsed_data.get("qualification_notes", "")
                )
            
            rule_engine = get_rule_engine()
            classification_result = rule_engine.classify(extracted_model)
            contract_nature = rule_engine._determine_contract_nature(extracted_model)
            total_budget = extracted_model.total_budget_vat or extracted_model.estimated_amount
            estimated_price_exc_vat = rule_engine._calculate_estimated_price_exc_vat(total_budget)
            
            classification = {
                "recommended_type": classification_result.recommended_type,
                "confidence": classification_result.confidence,
                "reason": classification_result.reason,
                "alternative_types": classification_result.alternative_types,
                "reason_trace": classification_result.reason_trace,
                "contract_nature": contract_nature,
                "purchase_type": extracted_model.procurement_type,
                "estimated_price_exc_vat": estimated_price_exc_vat,
                "applied_annex": rule_engine._determine_annex(estimated_price_exc_vat),
                "sme_restriction": rule_engine._determine_sme_restriction(estimated_price_exc_vat)
            }
        
        print(f"\nâœ… ë¶„ë¥˜ ê²°ê³¼:")
        print(f"  - ê³µê³  ë°©ì‹: {classification.get('recommended_type', 'N/A')}")
        print(f"  - ê³„ì•½ ì„±ê²©: {classification.get('contract_nature', 'N/A')}")
        print(f"  - ì¶”ì •ê°€ê²©(VAT ì œì™¸): {classification.get('estimated_price_exc_vat', 0):,.0f}ì›")
        print(f"  - ì ìš© ë³„í‘œ: {classification.get('applied_annex', 'N/A')}")
        print(f"  - ì¤‘ì†Œê¸°ì—… ì œí•œ: {classification.get('sme_restriction', 'N/A')}")

        # AgentState ì—…ë°ì´íŠ¸
        self.state.classification = classification
        self.state.transition_to("generate")

        return classification

    def run_generation(
        self,
        extracted_data: Dict[str, Any],
        template_id: str = None,
        announcement_type: str = None,
        law_references: str = ""
    ) -> str:
        """
        STEP 4: Document Assembly (Non-LLM Pipeline ë‹¨ê³„)
        
        í•µì‹¬ ì›ì¹™: "LLMì€ íŒë‹¨ë§Œ, ë¬¸ì„œ ìƒì„±ì€ ì½”ë“œê°€ í•œë‹¤"
        
        ì´ ë©”ì„œë“œëŠ” LLM Taskê°€ ì•„ë‹ˆë¼ Pipeline ë‹¨ê³„ì…ë‹ˆë‹¤:
        1. í…œí”Œë¦¿ íŒŒì¼ ì§ì ‘ ë¡œë“œ
        2. field_mapperë¡œ í”Œë ˆì´ìŠ¤í™€ë” ì¹˜í™˜ (Document Assembly)
        3. (ì„ íƒ) Generator Agentë¡œ ê²€ì¦/ë‹¤ë“¬ê¸° (USE_GENERATOR_AGENT=trueì¸ ê²½ìš°ë§Œ)
        
        Generator Agentì˜ ì—­í• :
        - âŒ ë¬¸ì„œ ìƒì„± (ì´ë¯¸ field_mapperê°€ ì™„ë£Œ)
        - âœ… ì„ íƒì  ê²€ì¦: í•„ìˆ˜ ìŠ¬ë¡¯ ëˆ„ë½ ì—¬ë¶€, ë¬¸ë§¥ ê²€ì¦
        - âœ… ì„ íƒì  ë‹¤ë“¬ê¸°: ë¬¸ì¥ íë¦„ ê°œì„  (ìœ„í—˜: í…œí”Œë¦¿ ìˆ˜ì • ê°€ëŠ¥)
        
        Args:
            extracted_data: ì¶”ì¶œëœ í‚¤ì›Œë“œ
            template_id: (ì‚¬ìš© ì•ˆ í•¨, í˜¸í™˜ì„± ìœ ì§€ìš©)
            announcement_type: ê³µê³  ìœ í˜• (í…œí”Œë¦¿ ì„ íƒìš©)

        Returns:
            ìƒì„±ëœ ê³µê³ ë¬¸ ë¬¸ìì—´ (field_mapper ê²°ê³¼ ë˜ëŠ” Generator Agent ê²°ê³¼)
        """
        from app.tools.template_selector import get_template_selector
        from app.tools.field_mapper import get_field_mapper
        from app.models.schemas import ClassificationResult

        # 1. í…œí”Œë¦¿ ì„ íƒ (ë¶„ë¥˜ ê²°ê³¼ ê¸°ë°˜)
        classification = self.state.classification or {}
        if not announcement_type:
            announcement_type = classification.get("recommended_type", "ì ê²©ì‹¬ì‚¬")

        template_selector = get_template_selector()
        
        # ClassificationResult ê°ì²´ ìƒì„± (í…œí”Œë¦¿ ì„ íƒìš©)
        classification_result = ClassificationResult(
            recommended_type=announcement_type,
            confidence=classification.get("confidence", 1.0),
            reason=classification.get("reason", ""),
            alternative_types=classification.get("alternative_types", [])
        )
        
        # ë„ì»¤ í™˜ê²½ì—ì„œëŠ” hwpx ì‚¬ìš© ë¶ˆê°€ (Windows ì „ìš©), ë§ˆí¬ë‹¤ìš´ í…œí”Œë¦¿ ì‚¬ìš©
        # ë¡œì»¬ Windows í™˜ê²½ì—ì„œëŠ” hwpx ì‚¬ìš© ê°€ëŠ¥
        import sys
        preferred_format = "md" if sys.platform != "win32" else "hwpx"
        template = template_selector.select_template(classification_result, preferred_format=preferred_format)
        print(f"âœ… í…œí”Œë¦¿ ì„ íƒ: {template.template_type} ({template.template_id}, í˜•ì‹: {template.template_format})")

        # ë¶„ë¥˜ ê²°ê³¼ë¥¼ extracted_dataì— í¬í•¨ (Generator Guardìš©)
        extracted_data_with_classification = extracted_data.copy()
        extracted_data_with_classification["classification"] = classification
        
        # í…œí”Œë¦¿ í˜•ì‹ì— ë”°ë¼ ë‹¤ë¥¸ ì²˜ë¦¬
        template_format = template.template_format or "md"
        
        if template_format == "hwpx":
            # HWPX í…œí”Œë¦¿ ì²˜ë¦¬ (Windows ì „ìš©, ë„ì»¤ì—ì„œëŠ” ì‚¬ìš© ë¶ˆê°€)
            try:
                from pathlib import Path
                from app.utils.hwpx_template_handler import fill_hwpx_template
                from app.tools.field_mapper import get_field_mapper
                
                field_mapper = get_field_mapper()
                mapped_data = field_mapper.map_extracted_to_template(
                    extracted_data_with_classification,
                    []  # HWPXëŠ” íŒŒë€ìƒ‰ í…ìŠ¤íŠ¸ì—ì„œ í•„ë“œ ì¶”ì¶œ
                )
                
                # HWPX í…œí”Œë¦¿ì— ë°ì´í„° ì±„ìš°ê¸°
                template_path = Path(template.template_path)
                hwpx_bytes = fill_hwpx_template(template_path, mapped_data)
                
                # ë°”ì´íŠ¸ë¥¼ base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ ë¬¸ìì—´ë¡œ ë°˜í™˜ (ì„ì‹œ)
                import base64
                generated_document = base64.b64encode(hwpx_bytes).decode('utf-8')
            except (ImportError, ModuleNotFoundError):
                # pyhwpxê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì€ ê²½ìš° (ë„ì»¤ í™˜ê²½) ë§ˆí¬ë‹¤ìš´ í…œí”Œë¦¿ìœ¼ë¡œ í´ë°±
                print("âš ï¸ HWPX í…œí”Œë¦¿ ì‚¬ìš© ë¶ˆê°€ (pyhwpx ë¯¸ì„¤ì¹˜). ë§ˆí¬ë‹¤ìš´ í…œí”Œë¦¿ìœ¼ë¡œ í´ë°±í•©ë‹ˆë‹¤.")
                template_format = "md"
                # ì•„ë˜ ë§ˆí¬ë‹¤ìš´ ì²˜ë¦¬ ë¡œì§ìœ¼ë¡œ ì§„í–‰
            
        elif template_format == "pdf":
            # PDF í…œí”Œë¦¿ ì²˜ë¦¬
            from pathlib import Path
            from app.utils.pdf_template_handler import fill_pdf_template
            from app.tools.field_mapper import get_field_mapper
            
            field_mapper = get_field_mapper()
            mapped_data = field_mapper.map_extracted_to_template(
                extracted_data_with_classification,
                []  # PDFëŠ” íŒŒë€ìƒ‰ í…ìŠ¤íŠ¸ì—ì„œ í•„ë“œ ì¶”ì¶œ
            )
            
            # PDF í…œí”Œë¦¿ì— ë°ì´í„° ì±„ìš°ê¸°
            template_path = Path(template.template_path)
            pdf_bytes = fill_pdf_template(template_path, mapped_data)
            
            # ë°”ì´íŠ¸ë¥¼ base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ ë¬¸ìì—´ë¡œ ë°˜í™˜ (ì„ì‹œ)
            import base64
            generated_document = base64.b64encode(pdf_bytes).decode('utf-8')
            
        else:
            # ============================================================
            # STEP 4: Document Assembly (Non-LLM Pipeline ë‹¨ê³„)
            # ============================================================
            # í•µì‹¬ ì›ì¹™: "LLMì€ íŒë‹¨ë§Œ, ë¬¸ì„œ ìƒì„±ì€ ì½”ë“œê°€ í•œë‹¤"
            #
            # ì´ ë‹¨ê³„ëŠ” LLM Taskê°€ ì•„ë‹ˆë¼ Pipeline ë‹¨ê³„ì…ë‹ˆë‹¤:
            # - í…œí”Œë¦¿ ë Œë”ë§: field_mapperê°€ ëª¨ë“  í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ì±„ì›€
            # - ë°ì´í„° ë³€í™˜: extracted_data â†’ í…œí”Œë¦¿ í•„ë“œ ë§¤í•‘
            # - íŒŒìƒ í•„ë“œ ìƒì„±: ë‚ ì§œ ê³„ì‚°, ë²•ë ¹ ë¬¸êµ¬ ìƒì„± ë“±
            #
            # Generator AgentëŠ” ì„ íƒì  ê²€ì¦/ë‹¤ë“¬ê¸° ìš©ë„ë¡œë§Œ ì‚¬ìš© ê°€ëŠ¥
            # (ê¸°ë³¸ê°’: false - ì‚¬ìš© ì•ˆ í•¨)
            # ============================================================
            
            field_mapper = get_field_mapper()
            
            # í…œí”Œë¦¿ì— ë°ì´í„° ì±„ìš°ê¸° (Document Assembly)
            print("ğŸ“ Document Assembly ì‹œì‘: í…œí”Œë¦¿ ë Œë”ë§ ì¤‘...")
            filled_template = field_mapper.fill_template(
                template.content,
                extracted_data_with_classification
            )
            
            # í”Œë ˆì´ìŠ¤í™€ë” ê²€ì¦: ë‚¨ì€ í”Œë ˆì´ìŠ¤í™€ë” í™•ì¸
            import re
            remaining_placeholders = re.findall(r'\{([a-zA-Z_][a-zA-Z0-9_]*)\}', filled_template)
            if remaining_placeholders:
                print(f"âš ï¸ ê²½ê³ : ë‹¤ìŒ í”Œë ˆì´ìŠ¤í™€ë”ê°€ ì±„ì›Œì§€ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {set(remaining_placeholders)}")
                # ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ìš°ê¸° ì‹œë„
                default_values = {
                    "qualification_review_target": "ì ê²©ì‹¬ì‚¬ ì œì™¸ëŒ€ìƒì…ë‹ˆë‹¤.",
                    "integrity_pledge_target": "ì²­ë ´ê³„ì•½ì´í–‰ ì„œì•½ì œ ëŒ€ìƒì…ë‹ˆë‹¤.",
                    "contract_method_detail": "ì¼ë°˜ê²½ìŸ(ì´ì•¡), ì „ìì…ì°°ëŒ€ìƒ ë¬¼í’ˆì…ë‹ˆë‹¤.",
                }
                for placeholder in set(remaining_placeholders):
                    if placeholder in default_values:
                        filled_template = filled_template.replace(
                            f"{{{placeholder}}}",
                            default_values[placeholder]
                        )
                        print(f"âœ… í”Œë ˆì´ìŠ¤í™€ë” {placeholder}ì— ê¸°ë³¸ê°’ ì ìš©")
                # ë‚¨ì€ í”Œë ˆì´ìŠ¤í™€ë” ì¬í™•ì¸
                remaining_placeholders = re.findall(r'\{([a-zA-Z_][a-zA-Z0-9_]*)\}', filled_template)
                if remaining_placeholders:
                    print(f"âš ï¸ ì—¬ì „íˆ ì±„ì›Œì§€ì§€ ì•Šì€ í”Œë ˆì´ìŠ¤í™€ë”: {set(remaining_placeholders)}")
            else:
                print("âœ… ëª¨ë“  í”Œë ˆì´ìŠ¤í™€ë”ê°€ ì±„ì›Œì¡ŒìŠµë‹ˆë‹¤.")

            # ============================================================
            # ì„ íƒì : Generator Agent (LLM ê¸°ë°˜ ê²€ì¦/ë‹¤ë“¬ê¸°)
            # ============================================================
            # ê¸°ë³¸ê°’: false (ì‚¬ìš© ì•ˆ í•¨)
            #
            # Generator Agentì˜ ì—­í• :
            # - âŒ ë¬¸ì„œ ìƒì„± (ì´ë¯¸ field_mapperê°€ ì™„ë£Œ)
            # - âœ… ì„ íƒì  ê²€ì¦: í•„ìˆ˜ ìŠ¬ë¡¯ ëˆ„ë½ ì—¬ë¶€, ë¬¸ë§¥ ê²€ì¦
            # - âœ… ì„ íƒì  ë‹¤ë“¬ê¸°: ë¬¸ì¥ íë¦„ ê°œì„  (ìœ„í—˜: í…œí”Œë¦¿ ìˆ˜ì • ê°€ëŠ¥)
            #
            # ì‚¬ìš© ì¡°ê±´:
            # - í…œí”Œë¦¿ì— ë¹„ì–´ ìˆëŠ” ë¬¸ì¥ êµ¬ì¡°ê°€ ìˆëŠ” ê²½ìš°
            # - {}ë¡œ í‘œí˜„ë˜ì§€ ì•Šì€ ë¶€ë¶„ì„ LLMì´ ë¬¸ë§¥ìƒ ë§Œë“¤ì–´ì•¼ í•˜ëŠ” ê²½ìš°
            # - í˜„ì¬ í…œí”Œë¦¿ì€ ëª¨ë“  ê°€ë³€ ì •ë³´ê°€ {}ë¡œ ëª…ì‹œë˜ì–´ ìˆìœ¼ë¯€ë¡œ ë¶ˆí•„ìš”
            #
            # í™œì„±í™” ë°©ë²•:
            # 1. í™˜ê²½ ë³€ìˆ˜: USE_GENERATOR_AGENT=true
            # 2. docker-compose.yml: - USE_GENERATOR_AGENT=true
            #
            # ì£¼ì˜: Generator Agent ì‚¬ìš© ì‹œ í…œí”Œë¦¿ì´ ì˜ë¦¬ê±°ë‚˜ ìˆ˜ì •ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ
            #       ì˜ë¦¼ ê°ì§€ ë¡œì§ì´ ìë™ìœ¼ë¡œ filled_templateë¥¼ fallbackìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
            # ============================================================
            use_generator_agent = os.getenv("USE_GENERATOR_AGENT", "false").lower() == "true"
            
            if use_generator_agent:
                print("âš ï¸ Generator Agent ì‚¬ìš© ì¤‘ (ì„ íƒì  ê²€ì¦/ë‹¤ë“¬ê¸° ëª¨ë“œ)")
                # Generatorê°€ ë¬¸ì„œ ê²€ì¦/ë‹¤ë“¬ê¸° (ë¬¸ì¥ ë‹¤ë“¬ê¸° í¬í•¨)
                generation_task = create_generation_task(
                    self.generator,
                    filled_template,  # ì´ë¯¸ ì±„ì›Œì§„ í…œí”Œë¦¿
                    extracted_data_with_classification,
                    classification  # Rule Engine ê²°ì •ê°’ (ê°€ë“œìš©)
                )

                # Generatorë§Œ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ë¬¸ì„œ ê²€ì¦/ë‹¤ë“¬ê¸°
                generation_crew = Crew(
                    agents=[self.generator],
                    tasks=[generation_task],
                    process=Process.sequential,
                    verbose=True
                )
                
                generation_result = generation_crew.kickoff()
                generated_document = str(generation_result)
            else:
                # Generator Agent ê±´ë„ˆë›°ê¸°: field_mapper ê²°ê³¼ë¥¼ ë°”ë¡œ ì‚¬ìš© (ê¸°ë³¸ ë™ì‘)
                # field_mapperê°€ ì´ë¯¸ ëª¨ë“  í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ì±„ì› ìœ¼ë¯€ë¡œ ì¶”ê°€ LLM í˜¸ì¶œ ë¶ˆí•„ìš”
                print("âœ… Document Assembly ì™„ë£Œ: field_mapper ê²°ê³¼ë¥¼ ë°”ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                print("   (Generator AgentëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ - USE_GENERATOR_AGENT=false)")
                generated_document = filled_template
            
            # ì‘ë‹µì´ ì˜ë ¸ëŠ”ì§€ í™•ì¸ (í…œí”Œë¦¿ì˜ ì£¼ìš” ì„¹ì…˜ í¬í•¨ ì—¬ë¶€)
            template_sections = [
                "ê²¬ì (ì…ì°°)ì— ë¶€ì¹˜ëŠ” ì‚¬í•­", "ê²¬ì (ì…ì°°) ë° ê³„ì•½ë°©ì‹", "ì…ì°°ì°¸ê°€ìê²©", 
                "ê³µë™ê³„ì•½", "ì˜ˆì •ê°€ê²©", "ì²­ë ´ê³„ì•½ì´í–‰", "ì…ì°°ë³´ì¦ê¸ˆ", 
                "ì…ì°°ë¬´íš¨", "í•˜ë„ê¸‰", "ê¸°íƒ€ì‚¬í•­", "ìœ„ì™€ ê°™ì´ ê³µê³ í•©ë‹ˆë‹¤"
            ]
            missing_sections = []
            for section in template_sections:
                if section not in generated_document:
                    missing_sections.append(section)
            
            # ì„¹ì…˜ ë²ˆí˜¸ í™•ì¸ (1~10ê¹Œì§€ ëª¨ë‘ ìˆì–´ì•¼ í•¨)
            section_numbers = []
            for i in range(1, 11):
                if f"## {i}." in generated_document or f"## {i}." in filled_template:
                    section_numbers.append(i)
            
            # í…œí”Œë¦¿ ê¸¸ì´ ëŒ€ë¹„ ìƒì„± ë¬¸ì„œ ê¸¸ì´ í™•ì¸ (80% ë¯¸ë§Œì´ë©´ ì˜ë¦¼ìœ¼ë¡œ ê°„ì£¼)
            template_length = len(filled_template)
            generated_length = len(generated_document)
            length_ratio = generated_length / template_length if template_length > 0 else 0
            
            # ë¬¸ì„œê°€ ì˜ë ¸ëŠ”ì§€ í™•ì¸
            is_truncated = False
            if missing_sections:
                print(f"âš ï¸ ê²½ê³ : ìƒì„±ëœ ë¬¸ì„œì—ì„œ ë‹¤ìŒ ì„¹ì…˜ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_sections}")
                is_truncated = True
            
            if length_ratio < 0.8:
                print(f"âš ï¸ ê²½ê³ : ë¬¸ì„œê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ (í…œí”Œë¦¿: {template_length}ì, ìƒì„±: {generated_length}ì, ë¹„ìœ¨: {length_ratio:.2%}). LLM ì‘ë‹µì´ ì˜ë ¸ì„ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.")
                is_truncated = True
            
            # "ìœ„ì™€ ê°™ì´ ê³µê³ í•©ë‹ˆë‹¤"ê°€ ì—†ìœ¼ë©´ ì˜ë¦¼ìœ¼ë¡œ ê°„ì£¼
            if "ìœ„ì™€ ê°™ì´ ê³µê³ í•©ë‹ˆë‹¤" not in generated_document:
                print("âš ï¸ ê²½ê³ : ë¬¸ì„œ ëë¶€ë¶„ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤ ('ìœ„ì™€ ê°™ì´ ê³µê³ í•©ë‹ˆë‹¤' ì—†ìŒ).")
                is_truncated = True
            
            # ì˜ë ¸ìœ¼ë©´ filled_templateë¥¼ fallbackìœ¼ë¡œ ì‚¬ìš©
            if is_truncated and use_generator_agent:
                print("âš ï¸ Generator ì‘ë‹µì´ ë¶ˆì™„ì „í•©ë‹ˆë‹¤. field_mapper ê²°ê³¼ë¥¼ fallbackìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                generated_document = filled_template
            
            # Validator Agent ì‚¬ìš© ì—¬ë¶€ í™•ì¸ (í™˜ê²½ ë³€ìˆ˜ë¡œ ì œì–´, ê¸°ë³¸ê°’: true - ë©€í‹° ì—ì´ì „íŠ¸ ì‚¬ìš©)
            use_validator_agent = os.getenv("USE_VALIDATOR_AGENT", "true").lower() == "true"
            
            if use_validator_agent:
                # Generator ê²°ê³¼ë¥¼ Validatorê°€ ê²€í†  (ë©€í‹° ì—ì´ì „íŠ¸ í˜‘ì—…)
                # ë²•ë ¹ ì°¸ì¡°ëŠ” íŒŒë¼ë¯¸í„°ë¡œ ì „ë‹¬ë°›ìŒ
                
                validation_task = create_validation_task(
                    self.validator,
                    generated_document,  # Generatorê°€ ìƒì„±í•œ ë¬¸ì„œ
                    law_references
                )
                
                # Validatorê°€ Generator ê²°ê³¼ë¥¼ ê²€í† 
                validation_crew = Crew(
                    agents=[self.validator],
                    tasks=[validation_task],
                    process=Process.sequential,
                    verbose=True
                )
                
                validation_result = validation_crew.kickoff()
                
                # ê²€ì¦ ê²°ê³¼ í™•ì¸
                try:
                    validation_data = json.loads(str(validation_result))
                    issues = validation_data.get("issues", [])
                    
                    if issues:
                        print(f"âš ï¸ Validatorê°€ {len(issues)}ê°œ ì´ìŠˆ ë°œê²¬:")
                        for issue in issues[:3]:  # ìµœëŒ€ 3ê°œë§Œ ì¶œë ¥
                            print(f"  - {issue.get('issue_type', 'N/A')}: {issue.get('suggestion', 'N/A')}")
                    else:
                        print("âœ… Validator ê²€ì¦ í†µê³¼")
                        
                except json.JSONDecodeError:
                    print("âš ï¸ Validator ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨ (ë¬¸ì„œëŠ” ìƒì„±ë¨)")
            else:
                print("âœ… Validator Agent ê±´ë„ˆë›°ê¸°: ê²€ì¦ ë‹¨ê³„ë¥¼ ìƒëµí•©ë‹ˆë‹¤.")
            
            # ìµœì¢… ë¬¸ì„œëŠ” Generator ê²°ê³¼ ì‚¬ìš©
            generated_document = generated_document

        # Generator ê²°ê³¼ ê²€ì¦ (Rule Guard)
        validation_issues = self._validate_generation_result(
            generated_document,
            classification
        )
        
        if validation_issues:
            print(f"âš ï¸ Generator ê²°ê³¼ ê²€ì¦ ì´ìŠˆ ë°œê²¬: {len(validation_issues)}ê°œ")
            for issue in validation_issues:
                print(f"  - {issue.get('issue_type')}: {issue.get('suggestion')}")

        # AgentState ì—…ë°ì´íŠ¸
        self.state.generated_document = generated_document
        self.state.transition_to("validate")

        return generated_document
    
    def _validate_generation_result(
        self,
        generated_document: str,
        classification: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        ìƒì„±ëœ ë¬¸ì„œê°€ ë¶„ë¥˜ ê²°ì •ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€ì¦ (Rule Guard)
        
        Args:
            generated_document: ìƒì„±ëœ ê³µê³ ë¬¸
            classification: ë¶„ë¥˜ ê²°ê³¼
            
        Returns:
            ê²€ì¦ ì´ìŠˆ ëª©ë¡
        """
        issues = []
        recommended_type = classification.get("recommended_type", "")
        applied_annex = classification.get("applied_annex")
        sme_restriction = classification.get("sme_restriction", "")
        
        # ê³µê³  ë°©ì‹ ë¶ˆì¼ì¹˜ ê²€ì‚¬
        if recommended_type == "ì ê²©ì‹¬ì‚¬":
            if "ì†Œì•¡ìˆ˜ì˜" in generated_document or "ì†Œì•¡" in generated_document:
                issues.append({
                    "issue_type": "ë¶„ë¥˜ ê²°ì • ë¶ˆì¼ì¹˜",
                    "severity": "high",
                    "current_text": "ì†Œì•¡ìˆ˜ì˜ ê´€ë ¨ í‘œí˜„ ë°œê²¬",
                    "suggestion": f"ê³µê³  ë°©ì‹ì´ Rule Engine ê²°ì •({recommended_type})ê³¼ ë‹¤ë¦…ë‹ˆë‹¤. 'ì ê²©ì‹¬ì‚¬' í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”."
                })
        elif recommended_type == "ì†Œì•¡ìˆ˜ì˜":
            if "ì ê²©ì‹¬ì‚¬" in generated_document:
                issues.append({
                    "issue_type": "ë¶„ë¥˜ ê²°ì • ë¶ˆì¼ì¹˜",
                    "severity": "high",
                    "current_text": "ì ê²©ì‹¬ì‚¬ ê´€ë ¨ í‘œí˜„ ë°œê²¬",
                    "suggestion": f"ê³µê³  ë°©ì‹ì´ Rule Engine ê²°ì •({recommended_type})ê³¼ ë‹¤ë¦…ë‹ˆë‹¤. 'ì†Œì•¡ìˆ˜ì˜' í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”."
                })
        
        # ë³„í‘œ ë¶ˆì¼ì¹˜ ê²€ì‚¬
        if applied_annex:
            if applied_annex not in generated_document:
                issues.append({
                    "issue_type": "ë³„í‘œ ëˆ„ë½",
                    "severity": "medium",
                    "suggestion": f"ì ìš© ë³„í‘œ({applied_annex})ê°€ ë¬¸ì„œì— ëª…ì‹œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                })
        
        return issues

    def run_validation(
        self,
        generated_document: str,
        law_references: str
    ) -> Dict[str, Any]:
        """
        STEP 5: ë²•ë ¹ ê²€ì¦

        Returns:
            ValidationResult í˜•ì‹ì˜ ë”•ì…”ë„ˆë¦¬
        """
        task = create_validation_task(
            self.validator,
            generated_document,
            law_references
        )

        crew = Crew(
            agents=[self.validator],
            tasks=[task],
            process=Process.sequential,
            verbose=True
        )

        result = crew.kickoff()

        try:
            validation_result = json.loads(str(result))
        except json.JSONDecodeError:
            validation_result = {
                "is_valid": False,
                "issues": [],
                "checked_laws": [],
                "timestamp": datetime.now().isoformat(),
                "raw_output": str(result)
            }

        # AgentState ì—…ë°ì´íŠ¸
        self.state.validation_issues = validation_result.get("issues", [])

        return validation_result

    def run_revision(
        self,
        original_document: str,
        validation_issues: list
    ) -> str:
        """
        STEP 6: ê²€ì¦ ì´ìŠˆ ë°˜ì˜í•˜ì—¬ ìˆ˜ì •

        Returns:
            ìˆ˜ì •ëœ ê³µê³ ë¬¸ ë¬¸ìì—´
        """
        task = create_revision_task(
            self.generator,  # ìˆ˜ì •ë„ generatorê°€ ë‹´ë‹¹
            original_document,
            validation_issues
        )

        crew = Crew(
            agents=[self.generator],
            tasks=[task],
            process=Process.sequential,
            verbose=True
        )

        result = crew.kickoff()
        revised_document = str(result)
        
        # Revision ê²°ê³¼ ê²€ì¦: ì›ë³¸ ë¬¸ì„œ ê¸¸ì´ ëŒ€ë¹„ í™•ì¸
        original_length = len(original_document)
        revised_length = len(revised_document)
        length_ratio = revised_length / original_length if original_length > 0 else 0
        
        # í•„ìˆ˜ ì„¹ì…˜ í™•ì¸
        required_sections = [
            "ìœ„ì™€ ê°™ì´ ê³µê³ í•©ë‹ˆë‹¤",
            "ê¸°íƒ€ì‚¬í•­",
            "ì…ì°°ë¬´íš¨",
            "ì…ì°°ë³´ì¦ê¸ˆ",
            "ì²­ë ´ê³„ì•½ì´í–‰",
            "ì˜ˆì •ê°€ê²©",
            "ê³µë™ê³„ì•½",
            "ì…ì°°ì°¸ê°€ìê²©"
        ]
        missing_sections = [s for s in required_sections if s not in revised_document]
        
        # Revisionì´ ë¬¸ì„œë¥¼ ì˜ëëŠ”ì§€ í™•ì¸
        if length_ratio < 0.8 or missing_sections:
            print(f"âš ï¸ ê²½ê³ : Revision ê²°ê³¼ê°€ ë¶ˆì™„ì „í•©ë‹ˆë‹¤ (ì›ë³¸: {original_length}ì, ìˆ˜ì •: {revised_length}ì, ë¹„ìœ¨: {length_ratio:.2%})")
            if missing_sections:
                print(f"âš ï¸ ëˆ„ë½ëœ ì„¹ì…˜: {missing_sections}")
            print("âš ï¸ ì›ë³¸ ë¬¸ì„œë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.")
            return original_document
        
        print(f"âœ… Revision ì™„ë£Œ (ì›ë³¸: {original_length}ì, ìˆ˜ì •: {revised_length}ì, ë¹„ìœ¨: {length_ratio:.2%})")

        # AgentState ì—…ë°ì´íŠ¸
        self.state.generated_document = revised_document
        self.state.increment_retry()

        return revised_document

    def run_full_pipeline(
        self,
        document_text: str,
        law_references: str = "",
        max_iterations: int = 10
    ) -> str:
        """
        ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ - ì™„ë²½í•œ ë¬¸ì„œê°€ ë‚˜ì˜¬ ë•Œê¹Œì§€ ë°˜ë³µ

        Args:
            document_text: ì›ë³¸ ë¬¸ì„œ í…ìŠ¤íŠ¸
            law_references: ë²•ë ¹ ì°¸ì¡° í…ìŠ¤íŠ¸
            max_iterations: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ (ë¬´í•œ ë£¨í”„ ë°©ì§€)

        Returns:
            ì™„ì„±ëœ ê³µê³ ë¬¸ ë¬¸ìì—´ (String)
        """
        # STEP 1: ì¶”ì¶œ
        extracted_data = self.run_extraction(document_text)

        # STEP 2: ë¶„ë¥˜
        classification = self.run_classification(extracted_data)

        # ë¶„ë¥˜ ê²°ê³¼ ì¶œë ¥
        print(f"ğŸ“‹ ë¶„ë¥˜ ê²°ê³¼: {classification.get('recommended_type')}")

        # STEP 3: ìƒì„± (í…œí”Œë¦¿ + ë°ì´í„° ë§¤í•‘ ë°©ì‹)
        # ê³µê³  ë°©ì‹ìœ¼ë¡œ í…œí”Œë¦¿ ì„ íƒ
        announcement_type = classification.get("recommended_type")
        
        # ì†Œì•¡ìˆ˜ì˜ëŠ” "ìµœì €ê°€ë‚™ì°°" í…œí”Œë¦¿ ì‚¬ìš©
        if announcement_type == "ì†Œì•¡ìˆ˜ì˜":
            announcement_type = "ìµœì €ê°€ë‚™ì°°"
        
        current_document = self.run_generation(
            extracted_data,
            announcement_type=announcement_type,
            law_references=law_references
        )

        # ============================================================
        # STEP 4: ê²€ì¦ ë° ìˆ˜ì • (ë©€í‹° ì—ì´ì „íŠ¸ í˜‘ì—…)
        # ============================================================
        # Validator Agentì™€ Generator Agentê°€ í˜‘ì—…í•˜ì—¬ ë¬¸ì„œë¥¼ ê²€ì¦í•˜ê³  ìˆ˜ì •í•©ë‹ˆë‹¤.
        # - Validator: ë²•ë ¹ ê²€ì¦ ë° ì´ìŠˆ ë°œê²¬
        # - Generator: ë°œê²¬ëœ ì´ìŠˆ ë°˜ì˜í•˜ì—¬ ë¬¸ì„œ ìˆ˜ì •
        # ============================================================
        use_validator_agent = os.getenv("USE_VALIDATOR_AGENT", "true").lower() == "true"
        
        if use_validator_agent:
            # ê²€ì¦ ìˆ˜í–‰ (Validator Agent)
            validation_result = self.run_validation(
                current_document,
                law_references
            )
            
            issues = validation_result.get("issues", [])
            
            # High severity ì´ìŠˆë§Œ í•„í„°ë§
            high_severity_issues = [issue for issue in issues if issue.get("severity") == "high"]
            
            if high_severity_issues:
                print(f"âš ï¸ High severity ì´ìŠˆ {len(high_severity_issues)}ê°œ ë°œê²¬ (ì „ì²´ {len(issues)}ê°œ)")
                print("ğŸ”„ Generator Agentê°€ Validatorì˜ ì´ìŠˆë¥¼ ë°˜ì˜í•˜ì—¬ ë¬¸ì„œ ìˆ˜ì • ì¤‘... (ë©€í‹° ì—ì´ì „íŠ¸ í˜‘ì—…)")
                # High severity ì´ìŠˆë§Œ ìˆ˜ì • (Generator Agentê°€ Validator ê²°ê³¼ë¥¼ ë°›ì•„ì„œ ìˆ˜ì •)
                current_document = self.run_revision(
                    current_document,
                    high_severity_issues  # High severityë§Œ ì „ë‹¬
                )
            elif issues:
                print(f"â„¹ï¸ Medium/Low severity ì´ìŠˆ {len(issues)}ê°œ ë°œê²¬ (ë¬´ì‹œí•˜ê³  ì§„í–‰)")
            else:
                print("âœ… ê²€ì¦ ì™„ë£Œ: ì´ìŠˆ ì—†ìŒ")
        else:
            print("âœ… Validator Agent ê±´ë„ˆë›°ê¸°: ê²€ì¦ ë‹¨ê³„ë¥¼ ìƒëµí•©ë‹ˆë‹¤.")

        # ìµœëŒ€ ë°˜ë³µ ë„ë‹¬ - ìµœì„ ì˜ ê²°ê³¼ ë°˜í™˜
        print(f"âš ï¸ ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜({max_iterations})ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. í˜„ì¬ ë²„ì „ì„ ë°˜í™˜í•©ë‹ˆë‹¤.")
        self.state.transition_to("complete")
        return current_document
